{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 预告\n",
    "<img src=\"https://s2.loli.net/2022/02/19/w7pbgVvONoA1U4I.png\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 数据操作 + 数据预处理\n",
    "\n",
    "## 数据操作\n",
    "\n",
    "\n",
    "## 数据操作实现\n",
    "- 创建tensor\n",
    "- 运算符运算$\\rightarrow$逐个元素操作;逻辑运算符：X==Y 二元张量\n",
    "- torch.cat(); x.sum() $\\rightarrow$ 始终是一个张量，可设置维度\n",
    "- 广播机制：3 * 1+1 * 2 $\\rightarrow$3 * 2\n",
    "- x[-1], x[1:3] 左闭右开，获取最后一个/XXX个元素\n",
    "- id(Y)// Z[:]=X+Y, X+=Y\n",
    "- A = X.numpy(), B = torch.tensor(A)\n",
    "- a, a.item()\n",
    "\n",
    "## 数据预处理\n",
    "- 写数据\n",
    "```python\n",
    "import os \n",
    "os.makedirs(os.path.join('...', '...'), exist_ok=True)\n",
    "path = os.path.join(os.path.join('', '', '...csv'))\n",
    "with open(path, 'w') as f:\n",
    "    f.write('this is a sentence\\n')  # 可以设置列名，以及数据样本\n",
    "```\n",
    "\n",
    "- 读数据并预处理\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "data = pd.read_csv('...csv')\n",
    "\n",
    "input_data, output_data = data.iloc[:, 0:2], data.iloc[2] # iloc   \n",
    "input_data = input_data.fillna(input_data.mean())   # fillna, mean\n",
    "# 法二：类别值或离散值\n",
    "input_data = pd.get_dummies(input_data, dummy_na=True)\n",
    "\n",
    "print(data.values)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 线性代数\n",
    "## 线性代数实现\n",
    "- 矩阵转置 A.T, A==A.T\n",
    "- B = A.clone()\n",
    "- 哈达玛积 A * B\n",
    "- A.sum(axis=0//axis=[0, 1])   (2,5,4)->(5,4)//(4) \n",
    "- A.mean(), A.sum()/A.numel()  ||  A.mean(axis=0) ../A.shape[0]\n",
    "- 保持维度：keepdim=True  $\\rightarrow$ 保存维度从而***广播***\n",
    "- A.cumsum(axis=0)\n",
    "- torch.dot(x,y)\n",
    "- torch.mv(A,x)//torch.mm(A,B)//torch.norm(u)、\n",
    "\n",
    "## 按特定轴求和\n",
    "keepdim $\\rightarrow$ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 矩阵运算\n",
    "- 亚导数：将导数拓展到不可微的函数\n",
    "\n",
    "<img src=\"https://s2.loli.net/2022/02/08/UFCj8LgbItqxh9z.png\" width=40%>\n",
    "\n",
    "- 梯度/偏导\n",
    "- 标量$\\rightarrow$向量：注意内积\n",
    "$\\frac{\\partial y}{\\partial \\textbf{x}}$  $\\leftarrow$ ***分子布局***\n",
    "<img src=\"https://s2.loli.net/2022/02/08/m8k5rEZR1XD6H2u.png\" width=70%>\n",
    "- 向量求导\n",
    "<img src=\"https://s2.loli.net/2022/02/08/BHMbOWntpSZIkrf.png\" width=60%>\n",
    "\n",
    "## 矩阵布局相关内容\n",
    "相关重要公式：\n",
    "$$\\frac{\\partial (\\textbf x^T\\textbf a)}{\\partial \\textbf x}=\\frac{\\partial (\\textbf a^T\\textbf x)}{\\partial \\textbf x}=\\textbf a$$ \n",
    "$$\\frac{\\partial (\\textbf x^T\\textbf x)}{\\partial \\textbf x}=2\\textbf x$$\n",
    "<font color=\"#cf6923\" size=4 face=\"黑体\">不是很明白的推导：</font>\n",
    "$$\\frac{\\partial(\\textbf x^T\\textbf A\\textbf x)}{\\partial \\textbf x}=\\textbf A\\textbf x+\\textbf A^T\\textbf x$$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 自动求导\n",
    "## 自动求导\n",
    "- 向量链式求导法则\n",
    "- 自动求导\n",
    "  - 符号求导/数值求导\n",
    "  - 正向/反向 $\\rightarrow$ 链式反则：【计算与内存复杂度】\n",
    "- 计算图\n",
    "  - 无环图：隐式构造/显式构造\n",
    "  \n",
    "## 自动求导实现\n",
    "- **【注意】：标量求导**\n",
    "\n",
    "```python\n",
    "x.requires_grad(True)\n",
    "x.grad\n",
    "y = torch.dot(x, x)  #这里标量\n",
    "y = x * x\n",
    "y = y.sum()  #转化为标量 ## u=y.detach() 在保存参数中常用！分出计算图\n",
    "\n",
    "y.backward()  \n",
    "x.grad\n",
    "```\n",
    "- 控制流\n",
    "\n",
    "## QA：\n",
    "*梯度累加*：[掘金：梯度累加Gradient Accumulation](https://juejin.cn/post/7041121387418746910)  -->batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 线性回归+基础优化算法\n",
    "## 线性回归\n",
    "- 凸函数-->梯度0***最***优解\n",
    "- 显式解//NPC问题\n",
    "\n",
    "## 基础优化算法\n",
    "- 梯度下降：沿反梯度方向更新参数求解\n",
    " - 超参数：学习率\n",
    " - 小批量随机梯度下降：超参数：批量大小\n",
    " \n",
    "## 线性回归从0实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.045818\n",
      "epoch 2, loss 0.000183\n",
      "epoch 3, loss 0.000052\n"
     ]
    }
   ],
   "source": [
    "## 流水线、模型、损失函数、优化器(小批量随机梯度下降)、（训练）\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch \n",
    "import d2l.torch as d2l\n",
    "import random\n",
    "# ---------生成数据---------\n",
    "def synthetic_data(w, b, num):\n",
    "    X = torch.normal(0, 1, (num, len(w)))\n",
    "    y = torch.matmul(X, w) + b        ## 我猜想这里有广播机制\n",
    "    #y = torch.mul(w, X) + b   ## 这个确确实实用了广播，mul与matmul\n",
    "                                # 我是脑残，区别mm,matmul,mul(对应位)\n",
    "    \n",
    "    y +=torch.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape(-1, 1)\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "ture_b = 4.2\n",
    "feats, labels = synthetic_data(true_w, ture_b, 1000)\n",
    "# 绘图展示\n",
    "d2l.set_figsize()\n",
    "# d2l.plt.scatter(feats[:,1].detach().numpy(), labels.detach().numpy(), 1)\n",
    "#d2l.plt.show()\n",
    "\n",
    "# --------读取小批量--------\n",
    "def data_iter(batch_size, feats, labels):  ## 切片使用，转化list\n",
    "    num = len(feats)   # len与shape不同\n",
    "    indices = list(range(num))\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num, batch_size):\n",
    "        batch_indices = torch.tensor(indices[i:min(i+batch_size, num)])\n",
    "        yield feats[batch_indices], labels[batch_indices] ## 需要在函数里\n",
    "\n",
    "batch_size = 10                                     ## 生成器\n",
    "for X, y in data_iter(batch_size, feats, labels):   ## 这里它是迭代器！\n",
    "   # print(X,'\\n',y)\n",
    "    break\n",
    "\n",
    "# 初始化模型参数\n",
    "w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)  ##需要梯度哦\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# --------定义模型--------\n",
    "def linreg(X, w, b):\n",
    "    \"\"\"线性回归模型\"\"\"\n",
    "    return torch.matmul(X, w) + b\n",
    "\n",
    "# ------定义损失函数-------\n",
    "def squared_loss(y_hat, y):\n",
    "    return (y_hat-y.reshape(y_hat.shape))**2 / 2\n",
    "\n",
    "# ------定义优化算法--------\n",
    "def sgd(params, lr, batch_size):\n",
    "    \"\"\"小批量随机梯度下降\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()\n",
    "\n",
    "# --------训练------------\n",
    "lr = 0.03\n",
    "num_epochs = 3\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, feats, labels):\n",
    "        l = loss(net(X, w, b), y)\n",
    "        l.sum().backward()     # 需要对向量累加\n",
    "        sgd([w, b], lr, batch_size)  # 可能batch不能整除\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        train_l = loss(net(feats, w, b), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Pytorch中的广播机制](https://blog.csdn.net/qq_42890800/article/details/115558389)\n",
    "- 广播：\n",
    "  - mul:对应位不同才可broadcast\n",
    "  - matmul:\n",
    "    - (2,5,3)×(1,3,4)-->(2,5,4) \n",
    "    - (5,3,4)×(4,2)-->(5,3,2) ; (2,1,3,4)×(5,4,2)-->(2,5,3,2) 最外：batch\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归的简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "tensor([[ 0.6364, -0.2699],\n",
      "        [ 0.8885,  0.5589],\n",
      "        [ 0.2375,  1.5755],\n",
      "        ...,\n",
      "        [-0.4887, -0.5486],\n",
      "        [-0.8089,  0.1564],\n",
      "        [-0.1770,  1.9138]])\n",
      "---------------\n",
      "[tensor([[-0.6318, -0.0919],\n",
      "        [ 1.5754,  0.2078],\n",
      "        [-0.1164,  0.4759],\n",
      "        [ 0.2420, -0.6593],\n",
      "        [ 0.2448,  0.3614],\n",
      "        [ 0.3636,  0.3045],\n",
      "        [-0.3006,  0.6859],\n",
      "        [ 1.5126,  0.0446],\n",
      "        [-1.2847,  0.5420],\n",
      "        [ 2.1005,  1.1867]]), tensor([[ 3.2523],\n",
      "        [ 6.6294],\n",
      "        [ 2.3482],\n",
      "        [ 6.9333],\n",
      "        [ 3.4617],\n",
      "        [ 3.8878],\n",
      "        [ 1.2768],\n",
      "        [ 7.0818],\n",
      "        [-0.2302],\n",
      "        [ 4.3627]])]\n",
      "---------------\n",
      "[tensor([[ 1.4120,  1.5849],\n",
      "        [-0.8478, -1.7627],\n",
      "        [ 0.2573, -2.4222],\n",
      "        [ 0.8154, -0.2647],\n",
      "        [ 0.0941,  1.0384],\n",
      "        [ 0.8885,  0.5589],\n",
      "        [ 1.5134, -0.5289],\n",
      "        [ 0.4915,  1.9502],\n",
      "        [-0.6139, -0.1207],\n",
      "        [ 0.1109, -0.9904]]), tensor([[ 1.6326],\n",
      "        [ 8.4981],\n",
      "        [12.9582],\n",
      "        [ 6.7353],\n",
      "        [ 0.8600],\n",
      "        [ 4.0762],\n",
      "        [ 9.0325],\n",
      "        [-1.4422],\n",
      "        [ 3.3833],\n",
      "        [ 7.8041]])]\n",
      "---------------\n",
      "[tensor([[-1.7057,  0.5751],\n",
      "        [-0.7908, -0.4033],\n",
      "        [-0.7103,  0.1586],\n",
      "        [ 0.0427, -0.5118],\n",
      "        [ 0.4939, -0.0304],\n",
      "        [-0.9410,  1.6169],\n",
      "        [-0.9635, -0.1411],\n",
      "        [-0.4412,  0.4948],\n",
      "        [ 1.5565, -1.5606],\n",
      "        [ 0.5681, -1.0913]]), tensor([[-1.1774],\n",
      "        [ 3.9751],\n",
      "        [ 2.2484],\n",
      "        [ 6.0250],\n",
      "        [ 5.3023],\n",
      "        [-3.1702],\n",
      "        [ 2.7462],\n",
      "        [ 1.6362],\n",
      "        [12.5993],\n",
      "        [ 9.0304]])]\n",
      "---------------\n",
      "[tensor([[ 0.7020,  1.7400],\n",
      "        [-0.1683, -0.0665],\n",
      "        [ 0.5826, -0.6967],\n",
      "        [-0.2647,  1.9937],\n",
      "        [ 0.3936,  0.4961],\n",
      "        [-1.7182, -1.0487],\n",
      "        [-0.2716,  0.5097],\n",
      "        [ 0.4798, -1.7221],\n",
      "        [-0.7380, -0.6981],\n",
      "        [-0.6481,  0.3755]]), tensor([[-0.3154],\n",
      "        [ 4.0694],\n",
      "        [ 7.7159],\n",
      "        [-3.1127],\n",
      "        [ 3.3040],\n",
      "        [ 4.3268],\n",
      "        [ 1.9239],\n",
      "        [11.0028],\n",
      "        [ 5.1054],\n",
      "        [ 1.6233]])]\n",
      "---------------\n",
      "[tensor([[-0.1329, -1.2404],\n",
      "        [-0.5416, -0.1549],\n",
      "        [-1.0529, -2.0893],\n",
      "        [-0.4112,  1.9672],\n",
      "        [-0.7668,  1.0123],\n",
      "        [ 0.8222,  1.8572],\n",
      "        [ 0.7596, -0.2903],\n",
      "        [ 0.6845, -1.6284],\n",
      "        [ 0.6828, -0.8270],\n",
      "        [ 1.1569, -1.0969]]), tensor([[ 8.1605],\n",
      "        [ 3.6446],\n",
      "        [ 9.2011],\n",
      "        [-3.3295],\n",
      "        [-0.7780],\n",
      "        [-0.4870],\n",
      "        [ 6.7009],\n",
      "        [11.1028],\n",
      "        [ 8.3838],\n",
      "        [10.2447]])]\n",
      "---------------\n",
      "[tensor([[-0.9253,  0.3915],\n",
      "        [ 1.3652, -1.5797],\n",
      "        [ 1.1946, -0.3543],\n",
      "        [-0.7016, -0.4045],\n",
      "        [-0.6821, -1.5866],\n",
      "        [ 0.0805, -0.9373],\n",
      "        [ 0.9063, -0.0090],\n",
      "        [ 1.3814, -0.1935],\n",
      "        [-0.7295,  0.9017],\n",
      "        [-0.3378,  0.1394]]), tensor([[ 1.0333],\n",
      "        [12.3018],\n",
      "        [ 7.8057],\n",
      "        [ 4.1659],\n",
      "        [ 8.2156],\n",
      "        [ 7.5530],\n",
      "        [ 6.0480],\n",
      "        [ 7.6115],\n",
      "        [-0.3120],\n",
      "        [ 3.0673]])]\n",
      "---------------\n",
      "[tensor([[-0.4982,  0.4509],\n",
      "        [-0.7305, -0.5901],\n",
      "        [ 0.2627, -0.6121],\n",
      "        [-1.6452, -0.6976],\n",
      "        [ 1.6193, -0.2968],\n",
      "        [ 0.4919,  1.1017],\n",
      "        [ 0.6278,  0.3352],\n",
      "        [-0.4693, -2.4563],\n",
      "        [-2.2087, -0.1913],\n",
      "        [ 0.0798,  0.2041]]), tensor([[ 1.6699],\n",
      "        [ 4.7436],\n",
      "        [ 6.8063],\n",
      "        [ 3.2865],\n",
      "        [ 8.4502],\n",
      "        [ 1.4238],\n",
      "        [ 4.3252],\n",
      "        [11.6010],\n",
      "        [ 0.4281],\n",
      "        [ 3.6617]])]\n",
      "---------------\n",
      "[tensor([[ 0.6691,  0.0393],\n",
      "        [-0.7502,  1.3069],\n",
      "        [ 0.5742, -0.9323],\n",
      "        [ 0.5365,  1.0473],\n",
      "        [-0.3160, -0.4960],\n",
      "        [-0.2728, -1.7319],\n",
      "        [ 0.7850,  0.2275],\n",
      "        [ 1.4742,  1.9655],\n",
      "        [ 0.5342, -0.0653],\n",
      "        [ 1.9377, -1.8025]]), tensor([[ 5.4133],\n",
      "        [-1.7538],\n",
      "        [ 8.5078],\n",
      "        [ 1.7126],\n",
      "        [ 5.2622],\n",
      "        [ 9.5390],\n",
      "        [ 4.9905],\n",
      "        [ 0.4634],\n",
      "        [ 5.4885],\n",
      "        [14.2036]])]\n",
      "---------------\n",
      "[tensor([[-0.0543,  0.4292],\n",
      "        [-0.3490, -0.3517],\n",
      "        [ 1.0390,  0.6796],\n",
      "        [-1.7720, -0.3443],\n",
      "        [ 1.5798,  0.0717],\n",
      "        [-1.7142, -1.9255],\n",
      "        [-0.5729, -2.4585],\n",
      "        [ 0.8206, -1.1514],\n",
      "        [ 0.4237, -0.3266],\n",
      "        [-0.4695,  0.2841]]), tensor([[ 2.6456],\n",
      "        [ 4.6955],\n",
      "        [ 3.9510],\n",
      "        [ 1.8252],\n",
      "        [ 7.1088],\n",
      "        [ 7.3142],\n",
      "        [11.4051],\n",
      "        [ 9.7655],\n",
      "        [ 6.1884],\n",
      "        [ 2.2837]])]\n",
      "---------------\n",
      "[tensor([[ 0.9683, -1.2611],\n",
      "        [-2.0037, -0.1301],\n",
      "        [-0.7815,  0.5745],\n",
      "        [-0.2997, -1.2548],\n",
      "        [ 0.0161,  1.2979],\n",
      "        [ 0.5182, -0.5739],\n",
      "        [ 0.6419,  0.2536],\n",
      "        [ 0.5391,  0.6012],\n",
      "        [-1.4321, -1.7291],\n",
      "        [ 1.6735,  0.2540]]), tensor([[10.4086],\n",
      "        [ 0.6355],\n",
      "        [ 0.6826],\n",
      "        [ 7.8704],\n",
      "        [-0.1630],\n",
      "        [ 7.1904],\n",
      "        [ 4.6289],\n",
      "        [ 3.2443],\n",
      "        [ 7.2116],\n",
      "        [ 6.6781]])]\n",
      "---------------\n",
      "[tensor([[ 0.3312, -0.0135],\n",
      "        [-1.2598,  0.1509],\n",
      "        [ 0.0586,  0.3095],\n",
      "        [-0.3520,  0.8776],\n",
      "        [-0.2023,  1.5772],\n",
      "        [ 1.3315,  1.2425],\n",
      "        [-1.1462, -0.8022],\n",
      "        [ 0.0087,  0.5331],\n",
      "        [-0.7831,  2.1946],\n",
      "        [ 0.0916, -0.0276]]), tensor([[ 4.9416],\n",
      "        [ 1.1659],\n",
      "        [ 3.2547],\n",
      "        [ 0.4937],\n",
      "        [-1.5802],\n",
      "        [ 2.6366],\n",
      "        [ 4.6519],\n",
      "        [ 2.4090],\n",
      "        [-4.8374],\n",
      "        [ 4.4899]])]\n",
      "---------------\n",
      "[tensor([[-0.2480,  0.0753],\n",
      "        [-1.4886, -0.7937],\n",
      "        [ 0.7829,  0.3992],\n",
      "        [-0.8210,  0.5285],\n",
      "        [-1.0531,  0.5627],\n",
      "        [-0.2883,  0.2453],\n",
      "        [ 0.3862, -1.0099],\n",
      "        [ 0.9240,  0.2395],\n",
      "        [ 0.1598, -1.4682],\n",
      "        [ 1.4579,  2.0923]]), tensor([[ 3.4328],\n",
      "        [ 3.9230],\n",
      "        [ 4.4157],\n",
      "        [ 0.7494],\n",
      "        [ 0.1997],\n",
      "        [ 2.7917],\n",
      "        [ 8.4232],\n",
      "        [ 5.2496],\n",
      "        [ 9.5277],\n",
      "        [-0.0218]])]\n",
      "---------------\n",
      "[tensor([[ 0.2955, -1.0716],\n",
      "        [ 1.6886,  0.7025],\n",
      "        [-0.5999,  0.2531],\n",
      "        [-0.0143, -1.0918],\n",
      "        [-0.1762, -0.2009],\n",
      "        [ 0.6506,  0.2775],\n",
      "        [ 0.2280,  0.1534],\n",
      "        [-0.4328,  0.9982],\n",
      "        [ 0.7080, -0.0344],\n",
      "        [ 0.0188, -0.8047]]), tensor([[ 8.4224],\n",
      "        [ 5.2074],\n",
      "        [ 2.1508],\n",
      "        [ 7.8870],\n",
      "        [ 4.5219],\n",
      "        [ 4.5622],\n",
      "        [ 4.1251],\n",
      "        [-0.0660],\n",
      "        [ 5.7524],\n",
      "        [ 6.9793]])]\n",
      "---------------\n",
      "[tensor([[ 1.2732, -1.0516],\n",
      "        [ 2.0648,  1.7076],\n",
      "        [-0.4885, -0.2244],\n",
      "        [ 0.6454,  1.8670],\n",
      "        [ 0.2197, -0.1609],\n",
      "        [-0.8147,  0.2263],\n",
      "        [-0.4771,  0.9986],\n",
      "        [-0.4885, -1.0323],\n",
      "        [-0.6665, -0.1510],\n",
      "        [ 0.5166, -0.6747]]), tensor([[10.3204],\n",
      "        [ 2.5140],\n",
      "        [ 3.9661],\n",
      "        [-0.8554],\n",
      "        [ 5.1783],\n",
      "        [ 1.8029],\n",
      "        [-0.1337],\n",
      "        [ 6.7251],\n",
      "        [ 3.3777],\n",
      "        [ 7.5233]])]\n",
      "---------------\n",
      "[tensor([[-0.1567, -1.1919],\n",
      "        [ 0.3823,  0.3185],\n",
      "        [ 0.6394, -0.1466],\n",
      "        [-0.9711, -1.1903],\n",
      "        [-0.3130,  2.1489],\n",
      "        [-0.3350,  0.4618],\n",
      "        [-0.9127, -1.3769],\n",
      "        [ 0.6604, -0.3735],\n",
      "        [ 1.0235, -0.6937],\n",
      "        [-0.9093,  0.1160]]), tensor([[ 7.9384],\n",
      "        [ 3.9049],\n",
      "        [ 5.9761],\n",
      "        [ 6.3059],\n",
      "        [-3.7359],\n",
      "        [ 1.9869],\n",
      "        [ 7.0516],\n",
      "        [ 6.7895],\n",
      "        [ 8.5933],\n",
      "        [ 1.9777]])]\n",
      "---------------\n",
      "[tensor([[-0.0094, -0.2680],\n",
      "        [-0.9613,  1.9488],\n",
      "        [-0.9262,  0.2308],\n",
      "        [-0.1490, -1.0243],\n",
      "        [-0.8089,  0.1564],\n",
      "        [ 0.8901,  1.4258],\n",
      "        [ 0.2325,  1.5294],\n",
      "        [-0.8272,  0.5061],\n",
      "        [ 0.3362, -1.3449],\n",
      "        [ 2.3053, -1.2275]]), tensor([[ 5.0958],\n",
      "        [-4.3600],\n",
      "        [ 1.5538],\n",
      "        [ 7.3967],\n",
      "        [ 2.0544],\n",
      "        [ 1.1326],\n",
      "        [-0.5414],\n",
      "        [ 0.8186],\n",
      "        [ 9.4558],\n",
      "        [12.9613]])]\n",
      "---------------\n",
      "[tensor([[-1.7451,  0.8161],\n",
      "        [-0.8965, -0.1071],\n",
      "        [-1.9323, -1.2912],\n",
      "        [-0.5879, -0.6005],\n",
      "        [ 0.4789, -1.1404],\n",
      "        [ 0.8691, -2.7603],\n",
      "        [ 0.2018,  1.7082],\n",
      "        [-0.1793, -0.5582],\n",
      "        [-0.9606, -0.2784],\n",
      "        [ 0.1103,  1.1830]]), tensor([[-2.0759],\n",
      "        [ 2.7728],\n",
      "        [ 4.7148],\n",
      "        [ 5.0769],\n",
      "        [ 9.0350],\n",
      "        [15.3117],\n",
      "        [-1.1929],\n",
      "        [ 5.7334],\n",
      "        [ 3.2012],\n",
      "        [ 0.4136]])]\n",
      "---------------\n",
      "[tensor([[ 1.5454, -0.8213],\n",
      "        [-0.6514,  0.5206],\n",
      "        [ 0.8789,  0.2011],\n",
      "        [-0.4505,  0.1743],\n",
      "        [-0.3040, -0.3890],\n",
      "        [-1.1161, -0.5459],\n",
      "        [ 0.2405, -0.2992],\n",
      "        [ 0.0017, -0.8373],\n",
      "        [ 1.2760, -0.6017],\n",
      "        [-1.0352,  0.3224]]), tensor([[10.0804],\n",
      "        [ 1.1176],\n",
      "        [ 5.2639],\n",
      "        [ 2.7154],\n",
      "        [ 4.9142],\n",
      "        [ 3.8125],\n",
      "        [ 5.7001],\n",
      "        [ 7.0354],\n",
      "        [ 8.7968],\n",
      "        [ 1.0251]])]\n",
      "---------------\n",
      "[tensor([[ 1.4284,  0.1884],\n",
      "        [-0.9551, -1.7944],\n",
      "        [ 0.4577, -0.1121],\n",
      "        [-1.0456, -0.2937],\n",
      "        [-0.0325, -0.1257],\n",
      "        [ 1.0564, -0.4615],\n",
      "        [ 1.0202,  1.1571],\n",
      "        [-0.5656,  1.5982],\n",
      "        [-1.0457, -0.5670],\n",
      "        [-0.2245,  0.2629]]), tensor([[ 6.4267],\n",
      "        [ 8.3862],\n",
      "        [ 5.5150],\n",
      "        [ 3.1192],\n",
      "        [ 4.5626],\n",
      "        [ 7.8803],\n",
      "        [ 2.3118],\n",
      "        [-2.3640],\n",
      "        [ 4.0456],\n",
      "        [ 2.8553]])]\n",
      "---------------\n",
      "[tensor([[ 0.0166, -1.3498],\n",
      "        [ 1.1077, -0.1834],\n",
      "        [-0.3503,  0.3024],\n",
      "        [ 0.5576,  1.5192],\n",
      "        [-0.9599, -0.3381],\n",
      "        [-0.8328,  1.1734],\n",
      "        [-1.4623, -1.7150],\n",
      "        [-2.5050, -0.6699],\n",
      "        [ 0.7032, -0.5790],\n",
      "        [ 1.8909, -0.0295]]), tensor([[ 8.8302],\n",
      "        [ 7.0470],\n",
      "        [ 2.4744],\n",
      "        [ 0.1463],\n",
      "        [ 3.4411],\n",
      "        [-1.4551],\n",
      "        [ 7.1080],\n",
      "        [ 1.4666],\n",
      "        [ 7.5778],\n",
      "        [ 8.0784]])]\n",
      "---------------\n",
      "[tensor([[ 0.9210, -1.2444],\n",
      "        [ 0.6578,  0.2319],\n",
      "        [ 0.1157, -0.2101],\n",
      "        [ 2.6097, -1.4551],\n",
      "        [ 1.2328,  1.6635],\n",
      "        [-0.3587, -0.3432],\n",
      "        [-1.5220, -2.2923],\n",
      "        [ 1.4757, -0.4652],\n",
      "        [-0.7873,  0.0222],\n",
      "        [ 0.9439, -0.6796]]), tensor([[10.2795],\n",
      "        [ 4.7168],\n",
      "        [ 5.1509],\n",
      "        [14.3629],\n",
      "        [ 1.0176],\n",
      "        [ 4.6448],\n",
      "        [ 8.9560],\n",
      "        [ 8.7495],\n",
      "        [ 2.5464],\n",
      "        [ 8.3910]])]\n",
      "---------------\n",
      "[tensor([[-0.3133,  1.0414],\n",
      "        [-1.1120,  0.6700],\n",
      "        [ 0.9933, -0.1370],\n",
      "        [-2.8522, -0.8558],\n",
      "        [-1.1985, -1.4304],\n",
      "        [-1.0021, -0.7469],\n",
      "        [-0.8723, -0.7198],\n",
      "        [ 0.7785, -0.9218],\n",
      "        [ 0.4202, -0.6362],\n",
      "        [ 0.7389, -0.1226]]), tensor([[ 0.0418],\n",
      "        [-0.3070],\n",
      "        [ 6.6758],\n",
      "        [ 1.3947],\n",
      "        [ 6.6696],\n",
      "        [ 4.7379],\n",
      "        [ 4.9127],\n",
      "        [ 8.8911],\n",
      "        [ 7.2170],\n",
      "        [ 6.0880]])]\n",
      "---------------\n",
      "[tensor([[ 1.8102, -0.6734],\n",
      "        [ 0.1931, -0.0121],\n",
      "        [-0.5290, -1.2057],\n",
      "        [-0.2419,  0.3044],\n",
      "        [-0.0287,  0.3058],\n",
      "        [ 0.1907, -0.8630],\n",
      "        [ 0.3013,  0.4805],\n",
      "        [ 0.0506, -0.8870],\n",
      "        [-0.9506, -0.1645],\n",
      "        [ 0.3892, -0.5359]]), tensor([[10.1011],\n",
      "        [ 4.6246],\n",
      "        [ 7.2423],\n",
      "        [ 2.6650],\n",
      "        [ 3.1200],\n",
      "        [ 7.4972],\n",
      "        [ 3.1739],\n",
      "        [ 7.3198],\n",
      "        [ 2.8682],\n",
      "        [ 6.7839]])]\n",
      "---------------\n",
      "[tensor([[-1.3246, -1.1777],\n",
      "        [-0.8211,  1.0323],\n",
      "        [-1.3449,  0.3914],\n",
      "        [-0.5096, -0.7462],\n",
      "        [-1.2947,  0.3228],\n",
      "        [-0.7853,  1.0759],\n",
      "        [ 1.0979, -0.3279],\n",
      "        [-0.2786, -1.1218],\n",
      "        [-0.3500,  1.6768],\n",
      "        [-0.6654,  1.3254]]), tensor([[ 5.5610],\n",
      "        [-0.9381],\n",
      "        [ 0.1763],\n",
      "        [ 5.7370],\n",
      "        [ 0.5096],\n",
      "        [-1.0058],\n",
      "        [ 7.5007],\n",
      "        [ 7.4717],\n",
      "        [-2.2076],\n",
      "        [-1.6194]])]\n",
      "---------------\n",
      "[tensor([[-0.5450,  0.1584],\n",
      "        [-0.4748, -0.4420],\n",
      "        [-2.5754, -0.4595],\n",
      "        [-0.4502,  0.0852],\n",
      "        [ 2.1469,  0.8140],\n",
      "        [ 0.3941, -1.8210],\n",
      "        [-0.4254, -0.3617],\n",
      "        [-0.5646,  1.4800],\n",
      "        [ 0.2943,  0.7311],\n",
      "        [-0.7741,  0.0927]]), tensor([[ 2.5811],\n",
      "        [ 4.7484],\n",
      "        [ 0.6049],\n",
      "        [ 3.0250],\n",
      "        [ 5.7241],\n",
      "        [11.1645],\n",
      "        [ 4.5946],\n",
      "        [-1.9715],\n",
      "        [ 2.3158],\n",
      "        [ 2.3411]])]\n",
      "---------------\n",
      "[tensor([[-1.6893,  1.2147],\n",
      "        [-0.0393,  0.7347],\n",
      "        [-0.3239,  1.3287],\n",
      "        [-0.4342,  0.1943],\n",
      "        [ 0.6711,  0.1783],\n",
      "        [ 0.0427, -0.7410],\n",
      "        [ 0.2912,  0.0994],\n",
      "        [ 1.5742,  1.0225],\n",
      "        [ 1.3722,  1.2628],\n",
      "        [-0.7492,  1.1005]]), tensor([[-3.3098],\n",
      "        [ 1.6254],\n",
      "        [-0.9729],\n",
      "        [ 2.6749],\n",
      "        [ 4.9356],\n",
      "        [ 6.8181],\n",
      "        [ 4.4457],\n",
      "        [ 3.8630],\n",
      "        [ 2.6523],\n",
      "        [-1.0436]])]\n",
      "---------------\n",
      "[tensor([[-1.4070, -0.0193],\n",
      "        [-0.5401,  1.5858],\n",
      "        [-1.0383,  0.5060],\n",
      "        [-0.6279, -0.2520],\n",
      "        [-0.6403, -0.1245],\n",
      "        [ 0.1627,  0.0092],\n",
      "        [ 0.9790,  0.5161],\n",
      "        [-1.5691, -1.1666],\n",
      "        [ 0.8662, -1.5436],\n",
      "        [-1.1284, -0.6536]]), tensor([[ 1.4729],\n",
      "        [-2.2823],\n",
      "        [ 0.4077],\n",
      "        [ 3.7895],\n",
      "        [ 3.3535],\n",
      "        [ 4.4895],\n",
      "        [ 4.3931],\n",
      "        [ 5.0304],\n",
      "        [11.1817],\n",
      "        [ 4.1786]])]\n",
      "---------------\n",
      "[tensor([[-1.4858, -2.1471],\n",
      "        [ 1.0710,  0.2439],\n",
      "        [-1.2621, -0.3900],\n",
      "        [-0.2444, -0.0030],\n",
      "        [ 0.0416, -1.5325],\n",
      "        [ 1.9427, -0.6840],\n",
      "        [-0.7487, -0.5992],\n",
      "        [-0.4524,  0.3668],\n",
      "        [ 1.3067, -0.3443],\n",
      "        [ 0.6691,  0.8131]]), tensor([[ 8.5401],\n",
      "        [ 5.5093],\n",
      "        [ 3.0010],\n",
      "        [ 3.7281],\n",
      "        [ 9.4903],\n",
      "        [10.4265],\n",
      "        [ 4.7390],\n",
      "        [ 2.0400],\n",
      "        [ 7.9838],\n",
      "        [ 2.7643]])]\n",
      "---------------\n",
      "[tensor([[-1.3347, -1.0711],\n",
      "        [-1.2215,  0.4530],\n",
      "        [ 0.4240,  0.0260],\n",
      "        [-1.0425,  0.1672],\n",
      "        [-0.7978, -0.0236],\n",
      "        [-0.3775, -0.0611],\n",
      "        [-0.0749,  0.1141],\n",
      "        [-0.0105, -0.2493],\n",
      "        [-0.0633, -0.1855],\n",
      "        [ 0.3965,  0.8028]]), tensor([[5.1702],\n",
      "        [0.2277],\n",
      "        [4.9765],\n",
      "        [1.5384],\n",
      "        [2.6683],\n",
      "        [3.6627],\n",
      "        [3.6864],\n",
      "        [5.0090],\n",
      "        [4.7039],\n",
      "        [2.2547]])]\n",
      "---------------\n",
      "[tensor([[-0.0640,  1.2613],\n",
      "        [-0.6951, -1.5426],\n",
      "        [-0.6039, -0.6183],\n",
      "        [ 0.9015,  0.1355],\n",
      "        [ 2.2938, -0.1565],\n",
      "        [ 0.1743, -0.3542],\n",
      "        [-1.2019,  1.7437],\n",
      "        [-0.0187, -0.1078],\n",
      "        [-0.7155, -1.8057],\n",
      "        [-0.3328,  0.9070]]), tensor([[-0.2263],\n",
      "        [ 8.0597],\n",
      "        [ 5.0873],\n",
      "        [ 5.5516],\n",
      "        [ 9.3189],\n",
      "        [ 5.7552],\n",
      "        [-4.1509],\n",
      "        [ 4.5231],\n",
      "        [ 8.9119],\n",
      "        [ 0.4517]])]\n",
      "---------------\n",
      "[tensor([[ 2.6257,  0.1183],\n",
      "        [ 0.0346, -1.1585],\n",
      "        [ 0.7508,  1.0800],\n",
      "        [ 0.4749, -0.8996],\n",
      "        [-0.1248,  0.6663],\n",
      "        [ 2.3829,  0.3054],\n",
      "        [ 2.5754,  0.5794],\n",
      "        [ 0.6352, -0.3345],\n",
      "        [ 1.7680,  1.1378],\n",
      "        [ 0.3908,  0.5122]]), tensor([[9.0548],\n",
      "        [8.2089],\n",
      "        [2.0452],\n",
      "        [8.2159],\n",
      "        [1.7011],\n",
      "        [7.9270],\n",
      "        [7.3917],\n",
      "        [6.6153],\n",
      "        [3.8730],\n",
      "        [3.2354]])]\n",
      "---------------\n",
      "[tensor([[ 1.9389,  0.8400],\n",
      "        [-0.8876,  0.6029],\n",
      "        [ 2.3076, -1.0768],\n",
      "        [ 0.4956, -0.1489],\n",
      "        [-0.7645,  0.6424],\n",
      "        [ 0.1284, -0.7513],\n",
      "        [ 1.0150, -0.0721],\n",
      "        [ 0.8567,  0.5925],\n",
      "        [-0.7225,  2.3376],\n",
      "        [-2.3489, -0.1605]]), tensor([[ 5.2293],\n",
      "        [ 0.3772],\n",
      "        [12.4848],\n",
      "        [ 5.7150],\n",
      "        [ 0.4925],\n",
      "        [ 7.0151],\n",
      "        [ 6.4757],\n",
      "        [ 3.9093],\n",
      "        [-5.1893],\n",
      "        [ 0.0436]])]\n",
      "---------------\n",
      "[tensor([[-0.4610, -0.1298],\n",
      "        [-1.3695, -1.9369],\n",
      "        [-2.0227,  1.6634],\n",
      "        [ 1.4180, -0.1907],\n",
      "        [-0.7108, -1.2772],\n",
      "        [ 0.6001, -0.0163],\n",
      "        [ 0.5228, -1.2975],\n",
      "        [-1.8439,  0.0930],\n",
      "        [ 0.4031, -0.0965],\n",
      "        [ 0.4751,  0.0786]]), tensor([[ 3.7286],\n",
      "        [ 8.0283],\n",
      "        [-5.5008],\n",
      "        [ 7.6919],\n",
      "        [ 7.1267],\n",
      "        [ 5.4401],\n",
      "        [ 9.6462],\n",
      "        [ 0.1980],\n",
      "        [ 5.3414],\n",
      "        [ 4.8632]])]\n",
      "---------------\n",
      "[tensor([[ 1.6159,  1.3172],\n",
      "        [-1.2939, -0.7148],\n",
      "        [ 0.1187, -0.7137],\n",
      "        [ 1.4444, -0.5136],\n",
      "        [ 0.7183,  0.9610],\n",
      "        [-0.5343,  0.0789],\n",
      "        [-1.2163,  0.9501],\n",
      "        [ 0.7424, -0.2722],\n",
      "        [ 0.5009,  0.8027],\n",
      "        [ 1.3458,  0.1692]]), tensor([[ 2.9423],\n",
      "        [ 4.0356],\n",
      "        [ 6.8574],\n",
      "        [ 8.8357],\n",
      "        [ 2.3821],\n",
      "        [ 2.8422],\n",
      "        [-1.4727],\n",
      "        [ 6.6148],\n",
      "        [ 2.4770],\n",
      "        [ 6.3126]])]\n",
      "---------------\n",
      "[tensor([[ 0.4431,  1.1308],\n",
      "        [ 0.3490,  0.5487],\n",
      "        [-0.3041,  1.6326],\n",
      "        [ 1.8230, -0.3567],\n",
      "        [ 0.3061, -0.0201],\n",
      "        [-0.5312,  1.5616],\n",
      "        [ 1.5940, -0.5205],\n",
      "        [-0.9208,  0.3257],\n",
      "        [-0.9811, -1.6481],\n",
      "        [ 0.1956, -0.5954]]), tensor([[ 1.2400],\n",
      "        [ 3.0433],\n",
      "        [-1.9796],\n",
      "        [ 9.0397],\n",
      "        [ 4.8915],\n",
      "        [-2.1648],\n",
      "        [ 9.1473],\n",
      "        [ 1.2516],\n",
      "        [ 7.8575],\n",
      "        [ 6.6006]])]\n",
      "---------------\n",
      "[tensor([[ 1.9199, -0.3208],\n",
      "        [ 1.3312,  0.5783],\n",
      "        [ 0.6540, -0.4323],\n",
      "        [ 1.3777,  1.1842],\n",
      "        [ 0.1823,  0.0646],\n",
      "        [ 0.6123, -0.2323],\n",
      "        [ 0.1813, -0.1442],\n",
      "        [-0.0354, -1.0801],\n",
      "        [-0.2958,  1.0217],\n",
      "        [ 1.6883,  0.3137]]), tensor([[9.1265],\n",
      "        [4.9038],\n",
      "        [6.9873],\n",
      "        [2.9374],\n",
      "        [4.3488],\n",
      "        [6.2176],\n",
      "        [5.0519],\n",
      "        [7.7949],\n",
      "        [0.1425],\n",
      "        [6.5164]])]\n",
      "---------------\n",
      "[tensor([[-0.6853,  1.0988],\n",
      "        [-0.9386, -0.4568],\n",
      "        [ 0.7166,  2.0417],\n",
      "        [ 1.0175,  0.9216],\n",
      "        [-1.9784,  0.9450],\n",
      "        [ 2.0430,  0.5986],\n",
      "        [-1.4931,  0.0142],\n",
      "        [-0.2320, -0.3488],\n",
      "        [ 0.1957, -0.3327],\n",
      "        [ 0.2103, -2.4695]]), tensor([[-0.8967],\n",
      "        [ 3.8754],\n",
      "        [-1.2962],\n",
      "        [ 3.1208],\n",
      "        [-2.9634],\n",
      "        [ 6.2482],\n",
      "        [ 1.1612],\n",
      "        [ 4.9226],\n",
      "        [ 5.7201],\n",
      "        [13.0017]])]\n",
      "---------------\n",
      "[tensor([[-1.1785,  1.0342],\n",
      "        [-0.9595,  0.7234],\n",
      "        [-0.3830,  1.0977],\n",
      "        [ 0.4080,  1.0134],\n",
      "        [-1.0801, -0.2313],\n",
      "        [ 1.8767,  0.1285],\n",
      "        [ 0.8069,  0.1089],\n",
      "        [ 0.2548, -0.3821],\n",
      "        [-0.6861,  0.5368],\n",
      "        [ 0.4085, -1.1191]]), tensor([[-1.6803],\n",
      "        [-0.1802],\n",
      "        [-0.3008],\n",
      "        [ 1.5664],\n",
      "        [ 2.8229],\n",
      "        [ 7.5102],\n",
      "        [ 5.4623],\n",
      "        [ 5.9955],\n",
      "        [ 0.9960],\n",
      "        [ 8.8384]])]\n",
      "---------------\n",
      "[tensor([[ 2.2363e-01,  4.4743e-01],\n",
      "        [ 3.9786e-01,  2.4792e-01],\n",
      "        [-2.1335e+00, -9.2884e-01],\n",
      "        [ 1.2188e-01, -1.0456e+00],\n",
      "        [-2.6659e+00, -3.4470e-04],\n",
      "        [ 8.2015e-01, -1.7522e+00],\n",
      "        [-1.7131e+00,  1.3386e+00],\n",
      "        [-5.1105e-01, -8.5580e-01],\n",
      "        [-1.5616e-02,  1.2385e-01],\n",
      "        [-7.1705e-02,  2.8862e+00]]), tensor([[ 3.1354],\n",
      "        [ 4.1614],\n",
      "        [ 3.0836],\n",
      "        [ 7.9931],\n",
      "        [-1.1301],\n",
      "        [11.7941],\n",
      "        [-3.7821],\n",
      "        [ 6.1086],\n",
      "        [ 3.7449],\n",
      "        [-5.7594]])]\n",
      "---------------\n",
      "[tensor([[ 0.4041,  0.5693],\n",
      "        [ 1.0230, -1.1598],\n",
      "        [-1.9934, -0.2093],\n",
      "        [ 1.0399, -0.3682],\n",
      "        [ 0.1835,  0.0476],\n",
      "        [-1.1992,  1.0543],\n",
      "        [-0.7790,  2.5419],\n",
      "        [ 1.9463, -0.3212],\n",
      "        [-0.3740,  1.1479],\n",
      "        [ 1.3770, -0.1504]]), tensor([[ 3.0715],\n",
      "        [10.1899],\n",
      "        [ 0.9247],\n",
      "        [ 7.5408],\n",
      "        [ 4.4011],\n",
      "        [-1.7856],\n",
      "        [-5.9948],\n",
      "        [ 9.1918],\n",
      "        [-0.4468],\n",
      "        [ 7.4825]])]\n",
      "---------------\n",
      "[tensor([[-1.2975, -1.1057],\n",
      "        [-1.8659, -0.9545],\n",
      "        [-0.1191, -0.5358],\n",
      "        [ 1.2796,  0.6084],\n",
      "        [-0.7047,  1.5393],\n",
      "        [ 0.6292,  1.3496],\n",
      "        [-1.2424, -1.0554],\n",
      "        [ 0.4099,  1.2972],\n",
      "        [-1.5206,  0.0774],\n",
      "        [ 0.3547,  0.2549]]), tensor([[ 5.3657],\n",
      "        [ 3.7209],\n",
      "        [ 5.7739],\n",
      "        [ 4.6874],\n",
      "        [-2.4431],\n",
      "        [ 0.8809],\n",
      "        [ 5.3016],\n",
      "        [ 0.6110],\n",
      "        [ 0.8891],\n",
      "        [ 4.0350]])]\n",
      "---------------\n",
      "[tensor([[-0.2366, -0.0651],\n",
      "        [ 1.8347,  0.9746],\n",
      "        [ 0.7144, -1.0557],\n",
      "        [ 0.2572,  0.1515],\n",
      "        [-0.5841,  0.7687],\n",
      "        [ 0.4394, -0.1248],\n",
      "        [-1.8313, -1.4684],\n",
      "        [ 0.7751, -0.4927],\n",
      "        [-0.7140,  0.2502],\n",
      "        [-0.3973, -2.4039]]), tensor([[ 3.9392],\n",
      "        [ 4.5570],\n",
      "        [ 9.2218],\n",
      "        [ 4.1869],\n",
      "        [ 0.4193],\n",
      "        [ 5.4981],\n",
      "        [ 5.5240],\n",
      "        [ 7.4329],\n",
      "        [ 1.9124],\n",
      "        [11.5925]])]\n",
      "---------------\n",
      "[tensor([[-1.0020, -1.0396],\n",
      "        [ 0.2291, -0.6180],\n",
      "        [-0.0201,  1.3002],\n",
      "        [ 1.0356,  0.1916],\n",
      "        [-0.1204, -0.9004],\n",
      "        [ 1.9969, -0.0886],\n",
      "        [ 0.4499, -1.5119],\n",
      "        [ 1.3349,  1.1583],\n",
      "        [-0.1091, -0.1480],\n",
      "        [ 0.2686, -0.2311]]), tensor([[ 5.7178],\n",
      "        [ 6.7611],\n",
      "        [-0.2519],\n",
      "        [ 5.6235],\n",
      "        [ 7.0275],\n",
      "        [ 8.5014],\n",
      "        [10.2411],\n",
      "        [ 2.9350],\n",
      "        [ 4.4802],\n",
      "        [ 5.5108]])]\n",
      "---------------\n",
      "[tensor([[ 1.0925,  0.8601],\n",
      "        [ 0.7963,  0.6539],\n",
      "        [-0.3254, -1.7647],\n",
      "        [-1.0772,  0.5902],\n",
      "        [-0.4690, -0.2967],\n",
      "        [ 1.3221, -1.0521],\n",
      "        [-2.3173,  0.6817],\n",
      "        [-0.5478,  1.2052],\n",
      "        [-1.6786,  0.0090],\n",
      "        [-0.2247,  0.4433]]), tensor([[ 3.4862],\n",
      "        [ 3.5493],\n",
      "        [ 9.5442],\n",
      "        [ 0.0364],\n",
      "        [ 4.2610],\n",
      "        [10.4146],\n",
      "        [-2.7548],\n",
      "        [-1.0103],\n",
      "        [ 0.8048],\n",
      "        [ 2.2552]])]\n",
      "---------------\n",
      "[tensor([[ 0.2579, -0.1817],\n",
      "        [-1.2068, -0.5252],\n",
      "        [-0.1364, -0.5592],\n",
      "        [ 0.6150,  0.0079],\n",
      "        [ 0.2051, -0.9240],\n",
      "        [ 0.8937,  1.3785],\n",
      "        [-0.4114,  0.9928],\n",
      "        [-0.7523,  0.8910],\n",
      "        [-0.8994, -1.0409],\n",
      "        [-0.9586, -1.7924]]), tensor([[ 5.3359e+00],\n",
      "        [ 3.5532e+00],\n",
      "        [ 5.8122e+00],\n",
      "        [ 5.3955e+00],\n",
      "        [ 7.7435e+00],\n",
      "        [ 1.3122e+00],\n",
      "        [-7.8346e-04],\n",
      "        [-3.2731e-01],\n",
      "        [ 5.9156e+00],\n",
      "        [ 8.3603e+00]])]\n",
      "---------------\n",
      "[tensor([[-1.0860, -0.4336],\n",
      "        [ 0.0485,  0.1590],\n",
      "        [-1.1110, -1.4101],\n",
      "        [ 0.7750, -0.7552],\n",
      "        [-0.6186,  0.5052],\n",
      "        [ 1.3517,  2.7069],\n",
      "        [-2.5375, -0.3818],\n",
      "        [ 0.2973, -0.4261],\n",
      "        [-0.7108,  1.1100],\n",
      "        [ 1.5823, -1.5345]]), tensor([[ 3.4929],\n",
      "        [ 3.7617],\n",
      "        [ 6.7627],\n",
      "        [ 8.3504],\n",
      "        [ 1.2568],\n",
      "        [-2.2973],\n",
      "        [ 0.4227],\n",
      "        [ 6.2463],\n",
      "        [-1.0169],\n",
      "        [12.5774]])]\n",
      "---------------\n",
      "[tensor([[ 1.1095,  0.4585],\n",
      "        [-0.6456,  0.6256],\n",
      "        [ 0.0543,  1.0554],\n",
      "        [ 1.3750,  0.3989],\n",
      "        [ 0.6994,  0.1948],\n",
      "        [-1.4439, -0.3986],\n",
      "        [ 0.7341, -0.7655],\n",
      "        [ 0.1895,  0.3852],\n",
      "        [ 0.2394, -1.6418],\n",
      "        [-0.4473, -0.4684]]), tensor([[ 4.8541],\n",
      "        [ 0.7765],\n",
      "        [ 0.7112],\n",
      "        [ 5.6063],\n",
      "        [ 4.9256],\n",
      "        [ 2.6657],\n",
      "        [ 8.2645],\n",
      "        [ 3.2735],\n",
      "        [10.2718],\n",
      "        [ 4.9037]])]\n",
      "---------------\n",
      "[tensor([[ 0.0883, -1.7932],\n",
      "        [-0.7648,  1.8427],\n",
      "        [-0.0938, -2.2961],\n",
      "        [-0.4716, -0.5603],\n",
      "        [ 0.2823, -0.5237],\n",
      "        [-1.5025,  0.8901],\n",
      "        [ 1.2653, -1.6783],\n",
      "        [ 1.0702, -0.8675],\n",
      "        [ 1.1603, -1.0026],\n",
      "        [-1.0933, -1.4183]]), tensor([[10.4795],\n",
      "        [-3.5989],\n",
      "        [11.8048],\n",
      "        [ 5.1628],\n",
      "        [ 6.5299],\n",
      "        [-1.8244],\n",
      "        [12.4372],\n",
      "        [ 9.2803],\n",
      "        [ 9.9510],\n",
      "        [ 6.8328]])]\n",
      "---------------\n",
      "[tensor([[-1.9462,  0.6551],\n",
      "        [-0.3538,  0.7752],\n",
      "        [-0.9754,  0.6950],\n",
      "        [-0.6858,  1.7802],\n",
      "        [-0.1707,  0.5182],\n",
      "        [-0.6109, -0.5099],\n",
      "        [ 0.7274, -1.5594],\n",
      "        [-0.2917, -0.5736],\n",
      "        [-1.4028,  0.6732],\n",
      "        [ 0.0991,  0.0661]]), tensor([[-1.9185],\n",
      "        [ 0.8437],\n",
      "        [-0.0988],\n",
      "        [-3.2342],\n",
      "        [ 2.0850],\n",
      "        [ 4.7191],\n",
      "        [10.9395],\n",
      "        [ 5.5606],\n",
      "        [-0.8973],\n",
      "        [ 4.1731]])]\n",
      "---------------\n",
      "[tensor([[-0.4887, -0.5486],\n",
      "        [ 0.0394, -1.1507],\n",
      "        [-0.9338,  1.5873],\n",
      "        [ 0.7161,  1.0973],\n",
      "        [ 0.8637, -1.1611],\n",
      "        [-1.0195, -0.0834],\n",
      "        [-0.8599,  1.0223],\n",
      "        [-0.2369, -0.8875],\n",
      "        [ 0.7378, -0.5439],\n",
      "        [ 0.2550,  0.3757]]), tensor([[ 5.0823],\n",
      "        [ 8.2255],\n",
      "        [-3.0692],\n",
      "        [ 1.9060],\n",
      "        [ 9.8793],\n",
      "        [ 2.4505],\n",
      "        [-0.9809],\n",
      "        [ 6.7373],\n",
      "        [ 7.5251],\n",
      "        [ 3.4108]])]\n",
      "---------------\n",
      "[tensor([[ 0.5728, -1.2855],\n",
      "        [-0.1761,  0.1864],\n",
      "        [ 0.2299,  1.7935],\n",
      "        [ 0.2092, -0.8396],\n",
      "        [ 1.8850,  0.9697],\n",
      "        [-0.6627, -1.0320],\n",
      "        [-0.3270,  0.2207],\n",
      "        [-1.8988, -0.8477],\n",
      "        [-0.8897, -0.2415],\n",
      "        [ 0.3363,  1.5015]]), tensor([[ 9.7105],\n",
      "        [ 3.2132],\n",
      "        [-1.4417],\n",
      "        [ 7.4816],\n",
      "        [ 4.6679],\n",
      "        [ 6.3766],\n",
      "        [ 2.7924],\n",
      "        [ 3.2916],\n",
      "        [ 3.2486],\n",
      "        [-0.2431]])]\n",
      "---------------\n",
      "[tensor([[-2.2721, -0.1691],\n",
      "        [-0.4562,  0.1524],\n",
      "        [-0.3171,  0.4228],\n",
      "        [-0.8831,  0.6349],\n",
      "        [ 0.1604,  0.1497],\n",
      "        [-1.1216, -0.6050],\n",
      "        [ 0.7516,  1.2116],\n",
      "        [-1.1680, -1.7683],\n",
      "        [-0.4048,  0.2311],\n",
      "        [ 0.9519, -0.5959]]), tensor([[0.2495],\n",
      "        [2.7885],\n",
      "        [2.1370],\n",
      "        [0.2513],\n",
      "        [4.0078],\n",
      "        [4.0177],\n",
      "        [1.5669],\n",
      "        [7.8763],\n",
      "        [2.6160],\n",
      "        [8.1317]])]\n",
      "---------------\n",
      "[tensor([[-0.8147,  1.5997],\n",
      "        [ 0.2170, -1.0777],\n",
      "        [ 1.2686,  1.4480],\n",
      "        [ 0.5545, -1.1691],\n",
      "        [-0.4558, -1.0693],\n",
      "        [ 0.0332, -0.6304],\n",
      "        [-0.5928,  1.1576],\n",
      "        [ 1.2505,  0.0335],\n",
      "        [ 0.0762,  1.5538],\n",
      "        [ 0.0291, -0.8775]]), tensor([[-2.8948],\n",
      "        [ 8.2855],\n",
      "        [ 1.8310],\n",
      "        [ 9.2858],\n",
      "        [ 6.9008],\n",
      "        [ 6.4106],\n",
      "        [-0.9102],\n",
      "        [ 6.5826],\n",
      "        [-0.9284],\n",
      "        [ 7.2492]])]\n",
      "---------------\n",
      "[tensor([[ 0.5691,  0.3324],\n",
      "        [ 0.3686, -0.8329],\n",
      "        [-0.6884,  1.2389],\n",
      "        [-0.7407,  0.4335],\n",
      "        [ 1.2366,  0.5891],\n",
      "        [-0.5018, -0.3543],\n",
      "        [ 1.4407, -0.2195],\n",
      "        [-0.4446,  0.8328],\n",
      "        [-2.3011, -1.6730],\n",
      "        [-1.0372, -0.6678]]), tensor([[ 4.1831],\n",
      "        [ 7.7791],\n",
      "        [-1.3869],\n",
      "        [ 1.2488],\n",
      "        [ 4.6908],\n",
      "        [ 4.4052],\n",
      "        [ 7.8345],\n",
      "        [ 0.4703],\n",
      "        [ 5.2875],\n",
      "        [ 4.3992]])]\n",
      "---------------\n",
      "[tensor([[ 0.5621, -0.1077],\n",
      "        [ 0.4942,  1.3201],\n",
      "        [ 0.7841,  0.1908],\n",
      "        [-0.0937, -1.3658],\n",
      "        [ 1.0151, -1.0068],\n",
      "        [-0.3060, -1.4154],\n",
      "        [ 0.0053, -1.5893],\n",
      "        [ 1.7159, -0.2706],\n",
      "        [-0.4655, -1.4794],\n",
      "        [-0.1298, -0.2280]]), tensor([[5.6933],\n",
      "        [0.7125],\n",
      "        [5.1279],\n",
      "        [8.6794],\n",
      "        [9.6521],\n",
      "        [8.4116],\n",
      "        [9.6202],\n",
      "        [8.5544],\n",
      "        [8.2969],\n",
      "        [4.7079]])]\n",
      "---------------\n",
      "[tensor([[-0.7455,  1.5562],\n",
      "        [ 1.0146,  0.7253],\n",
      "        [-0.9331,  1.0737],\n",
      "        [-1.0738, -1.1393],\n",
      "        [ 0.1805, -0.6465],\n",
      "        [ 0.9345,  0.1453],\n",
      "        [ 0.1581, -0.6728],\n",
      "        [ 0.5703,  0.4794],\n",
      "        [ 0.2886, -0.2393],\n",
      "        [ 1.1124, -1.4561]]), tensor([[-2.5721],\n",
      "        [ 3.7772],\n",
      "        [-1.3136],\n",
      "        [ 5.9159],\n",
      "        [ 6.7732],\n",
      "        [ 5.5820],\n",
      "        [ 6.8245],\n",
      "        [ 3.7137],\n",
      "        [ 5.5887],\n",
      "        [11.3773]])]\n",
      "---------------\n",
      "[tensor([[ 0.4385, -1.5717],\n",
      "        [ 0.2245, -0.9858],\n",
      "        [-1.5640,  0.4711],\n",
      "        [-0.9920,  1.2836],\n",
      "        [-1.1022, -1.7735],\n",
      "        [ 0.5697,  0.4076],\n",
      "        [-1.3817,  0.2987],\n",
      "        [-0.3114,  0.3414],\n",
      "        [-0.7891,  0.8237],\n",
      "        [-1.3537, -0.0199]]), tensor([[10.4131],\n",
      "        [ 7.9913],\n",
      "        [-0.5429],\n",
      "        [-2.1592],\n",
      "        [ 8.0208],\n",
      "        [ 3.9478],\n",
      "        [ 0.4136],\n",
      "        [ 2.4071],\n",
      "        [-0.1657],\n",
      "        [ 1.5570]])]\n",
      "---------------\n",
      "[tensor([[ 1.4637, -0.0752],\n",
      "        [-0.2187, -0.7073],\n",
      "        [-0.5978,  0.9566],\n",
      "        [-0.8461, -0.9655],\n",
      "        [-0.3090, -0.3828],\n",
      "        [ 1.6330, -0.6714],\n",
      "        [ 0.3303, -1.0981],\n",
      "        [ 0.2936, -0.2987],\n",
      "        [-2.9658, -0.9000],\n",
      "        [ 0.6445,  0.4386]]), tensor([[ 7.3843],\n",
      "        [ 6.1843],\n",
      "        [-0.2548],\n",
      "        [ 5.7892],\n",
      "        [ 4.8758],\n",
      "        [ 9.7355],\n",
      "        [ 8.5988],\n",
      "        [ 5.8087],\n",
      "        [ 1.3301],\n",
      "        [ 3.9998]])]\n",
      "---------------\n",
      "[tensor([[-0.2869, -2.0575],\n",
      "        [ 0.6662, -1.9600],\n",
      "        [-1.0199,  1.5505],\n",
      "        [-0.8989, -0.1349],\n",
      "        [ 0.0792, -1.5867],\n",
      "        [-1.3419, -1.6277],\n",
      "        [ 0.6452,  1.0878],\n",
      "        [-0.4928, -1.0071],\n",
      "        [-0.5927, -0.4997],\n",
      "        [ 0.3567, -1.0910]]), tensor([[10.6228],\n",
      "        [12.2013],\n",
      "        [-3.1063],\n",
      "        [ 2.8350],\n",
      "        [ 9.7390],\n",
      "        [ 7.0583],\n",
      "        [ 1.7890],\n",
      "        [ 6.6405],\n",
      "        [ 4.7229],\n",
      "        [ 8.6457]])]\n",
      "---------------\n",
      "[tensor([[ 1.4140, -1.5454],\n",
      "        [ 1.2337, -0.8612],\n",
      "        [ 1.6861, -0.0323],\n",
      "        [ 0.8619, -1.3266],\n",
      "        [-0.4393,  0.0664],\n",
      "        [ 0.4027, -0.2324],\n",
      "        [-0.2949, -0.0729],\n",
      "        [ 0.9854,  0.6991],\n",
      "        [ 0.2252,  0.0666],\n",
      "        [ 0.6679,  0.1479]]), tensor([[12.3043],\n",
      "        [ 9.6157],\n",
      "        [ 7.6857],\n",
      "        [10.4534],\n",
      "        [ 3.1051],\n",
      "        [ 5.7991],\n",
      "        [ 3.8700],\n",
      "        [ 3.7947],\n",
      "        [ 4.4127],\n",
      "        [ 5.0390]])]\n",
      "---------------\n",
      "[tensor([[ 2.2020,  0.2550],\n",
      "        [ 0.2413,  1.0081],\n",
      "        [-1.3157,  1.8345],\n",
      "        [-1.1530,  1.1549],\n",
      "        [ 0.7410, -1.1883],\n",
      "        [ 1.3534, -0.5179],\n",
      "        [-0.2927,  0.1226],\n",
      "        [ 0.8436,  0.2568],\n",
      "        [ 0.1946,  0.6374],\n",
      "        [ 0.3779, -0.3744]]), tensor([[ 7.7425],\n",
      "        [ 1.2683],\n",
      "        [-4.6600],\n",
      "        [-2.0359],\n",
      "        [ 9.7304],\n",
      "        [ 8.6503],\n",
      "        [ 3.1929],\n",
      "        [ 5.0114],\n",
      "        [ 2.4301],\n",
      "        [ 6.2436]])]\n",
      "---------------\n",
      "[tensor([[ 0.0033, -0.0259],\n",
      "        [-1.3792,  1.2832],\n",
      "        [-0.7090, -0.8909],\n",
      "        [ 0.8948,  1.0729],\n",
      "        [-0.4066,  1.2201],\n",
      "        [-0.9958,  0.0889],\n",
      "        [ 1.6689, -0.1787],\n",
      "        [ 0.7349,  0.2909],\n",
      "        [-0.7700, -1.4892],\n",
      "        [-0.8447,  1.5695]]), tensor([[ 4.2972],\n",
      "        [-2.9221],\n",
      "        [ 5.8062],\n",
      "        [ 2.3361],\n",
      "        [-0.7653],\n",
      "        [ 1.8996],\n",
      "        [ 8.1423],\n",
      "        [ 4.6736],\n",
      "        [ 7.7232],\n",
      "        [-2.8291]])]\n",
      "---------------\n",
      "[tensor([[ 6.2409e-01, -2.3600e+00],\n",
      "        [-9.6510e-01, -7.5714e-01],\n",
      "        [-6.1781e-02,  2.0664e-01],\n",
      "        [-6.2351e-01,  7.5355e-01],\n",
      "        [-8.0519e-01, -5.7686e-01],\n",
      "        [ 7.0436e-01,  1.0990e+00],\n",
      "        [-1.2825e+00, -9.9952e-04],\n",
      "        [-1.1246e+00, -3.1390e-01],\n",
      "        [ 8.2875e-01,  1.4689e+00],\n",
      "        [ 9.1092e-01, -1.2809e+00]]), tensor([[13.4682],\n",
      "        [ 4.8382],\n",
      "        [ 3.3587],\n",
      "        [ 0.3769],\n",
      "        [ 4.5649],\n",
      "        [ 1.8739],\n",
      "        [ 1.6410],\n",
      "        [ 3.0029],\n",
      "        [ 0.8631],\n",
      "        [10.3799]])]\n",
      "---------------\n",
      "[tensor([[ 2.3487,  0.2564],\n",
      "        [ 1.2148, -1.8991],\n",
      "        [ 0.6854,  1.0382],\n",
      "        [ 1.1604, -0.7865],\n",
      "        [ 1.9472,  1.5391],\n",
      "        [ 1.0434, -1.0097],\n",
      "        [ 0.2345,  3.0010],\n",
      "        [-1.6724, -1.0631],\n",
      "        [ 0.1601,  1.0976],\n",
      "        [ 0.3812, -0.0996]]), tensor([[ 8.0225],\n",
      "        [13.1045],\n",
      "        [ 2.0326],\n",
      "        [ 9.2039],\n",
      "        [ 2.8538],\n",
      "        [ 9.7161],\n",
      "        [-5.5171],\n",
      "        [ 4.4616],\n",
      "        [ 0.7754],\n",
      "        [ 5.2905]])]\n",
      "---------------\n",
      "[tensor([[ 0.3720, -0.0566],\n",
      "        [ 1.0129,  1.1281],\n",
      "        [-0.9625, -1.1835],\n",
      "        [ 1.1861,  1.7614],\n",
      "        [ 0.0552,  0.3045],\n",
      "        [ 0.5546,  0.9689],\n",
      "        [-0.6814,  0.5521],\n",
      "        [ 0.2515, -0.6040],\n",
      "        [-0.5101, -0.7427],\n",
      "        [ 1.2191,  1.1492]]), tensor([[5.1214],\n",
      "        [2.3839],\n",
      "        [6.2993],\n",
      "        [0.5890],\n",
      "        [3.2742],\n",
      "        [2.0096],\n",
      "        [0.9669],\n",
      "        [6.7661],\n",
      "        [5.7086],\n",
      "        [2.7135]])]\n",
      "---------------\n",
      "[tensor([[ 0.2628, -1.4129],\n",
      "        [ 0.3091, -0.8829],\n",
      "        [-0.0131,  1.7770],\n",
      "        [ 0.1706, -1.0343],\n",
      "        [ 1.3626, -0.7706],\n",
      "        [ 0.0302, -0.1843],\n",
      "        [ 1.0601,  0.8440],\n",
      "        [-0.5221, -1.1458],\n",
      "        [ 0.9871, -1.0051],\n",
      "        [ 0.2959, -0.8821]]), tensor([[ 9.5141],\n",
      "        [ 7.8291],\n",
      "        [-1.8559],\n",
      "        [ 8.0397],\n",
      "        [ 9.5402],\n",
      "        [ 4.8803],\n",
      "        [ 3.4525],\n",
      "        [ 7.0428],\n",
      "        [ 9.6171],\n",
      "        [ 7.7895]])]\n",
      "---------------\n",
      "[tensor([[ 0.1788, -2.2440],\n",
      "        [-0.0138, -0.6002],\n",
      "        [ 1.2205,  0.0691],\n",
      "        [ 0.6478,  1.1382],\n",
      "        [ 2.9403,  0.1012],\n",
      "        [-0.3777,  0.2162],\n",
      "        [-0.4846,  0.6821],\n",
      "        [-2.0235, -0.0580],\n",
      "        [-1.1943,  1.8660],\n",
      "        [ 1.3222, -0.3146]]), tensor([[12.2017],\n",
      "        [ 6.2081],\n",
      "        [ 6.4065],\n",
      "        [ 1.6254],\n",
      "        [ 9.7330],\n",
      "        [ 2.7040],\n",
      "        [ 0.9120],\n",
      "        [ 0.3344],\n",
      "        [-4.5195],\n",
      "        [ 7.8969]])]\n",
      "---------------\n",
      "[tensor([[ 0.4630, -0.7504],\n",
      "        [-0.0852, -1.6541],\n",
      "        [ 1.1616, -1.5544],\n",
      "        [ 0.3999,  0.3220],\n",
      "        [-1.9648,  0.8384],\n",
      "        [ 0.8348, -0.3745],\n",
      "        [-0.1752, -0.6889],\n",
      "        [-1.5081,  0.3348],\n",
      "        [ 0.8236,  0.0687],\n",
      "        [-0.3977, -0.4003]]), tensor([[ 7.6937],\n",
      "        [ 9.6435],\n",
      "        [11.8005],\n",
      "        [ 3.9044],\n",
      "        [-2.5933],\n",
      "        [ 7.1397],\n",
      "        [ 6.2004],\n",
      "        [ 0.0551],\n",
      "        [ 5.6080],\n",
      "        [ 4.7617]])]\n",
      "---------------\n",
      "[tensor([[-0.7644,  0.6387],\n",
      "        [-1.3867, -2.3696],\n",
      "        [-1.0138, -0.4068],\n",
      "        [-0.9023, -0.0386],\n",
      "        [ 0.6681, -2.0371],\n",
      "        [ 0.3513,  0.9952],\n",
      "        [-1.1115,  1.0705],\n",
      "        [ 1.6478,  1.0809],\n",
      "        [ 0.1639,  0.3180],\n",
      "        [-0.0758,  0.0882]]), tensor([[ 0.4989],\n",
      "        [ 9.4777],\n",
      "        [ 3.5568],\n",
      "        [ 2.5336],\n",
      "        [12.4631],\n",
      "        [ 1.5140],\n",
      "        [-1.6767],\n",
      "        [ 3.8301],\n",
      "        [ 3.4572],\n",
      "        [ 3.7526]])]\n",
      "---------------\n",
      "[tensor([[ 0.1045,  1.5116],\n",
      "        [-0.0289, -0.5708],\n",
      "        [ 0.4729,  0.6646],\n",
      "        [-0.3217, -0.0980],\n",
      "        [-0.6018, -0.7031],\n",
      "        [ 0.0451, -1.2172],\n",
      "        [ 0.2074, -1.0358],\n",
      "        [-0.4996, -0.3505],\n",
      "        [ 0.9427,  0.1168],\n",
      "        [-1.3541,  0.3957]]), tensor([[-0.7522],\n",
      "        [ 6.0816],\n",
      "        [ 2.8834],\n",
      "        [ 3.8877],\n",
      "        [ 5.3902],\n",
      "        [ 8.4202],\n",
      "        [ 8.1416],\n",
      "        [ 4.3897],\n",
      "        [ 5.6910],\n",
      "        [ 0.1314]])]\n",
      "---------------\n",
      "[tensor([[ 2.4533, -0.3225],\n",
      "        [-0.7133, -0.0312],\n",
      "        [-0.3793, -1.0239],\n",
      "        [ 2.0828, -0.1457],\n",
      "        [ 0.6364, -0.2699],\n",
      "        [ 0.6978, -0.2477],\n",
      "        [-0.1186, -0.4958],\n",
      "        [-1.3114,  0.1149],\n",
      "        [-1.2705,  0.1040],\n",
      "        [-0.5518,  1.1456]]), tensor([[10.2002],\n",
      "        [ 2.8941],\n",
      "        [ 6.9350],\n",
      "        [ 8.8679],\n",
      "        [ 6.4082],\n",
      "        [ 6.4476],\n",
      "        [ 5.6496],\n",
      "        [ 1.1940],\n",
      "        [ 1.2977],\n",
      "        [-0.8111]])]\n",
      "---------------\n",
      "[tensor([[ 0.3528,  0.4075],\n",
      "        [-0.0581,  0.8238],\n",
      "        [ 1.8279,  1.4781],\n",
      "        [-0.6755, -1.3745],\n",
      "        [-0.0647,  0.2878],\n",
      "        [-1.1121,  0.1484],\n",
      "        [-1.1438,  0.9897],\n",
      "        [-0.1770,  1.9138],\n",
      "        [ 0.3277,  2.1846],\n",
      "        [ 1.2399,  1.2771]]), tensor([[ 3.5116],\n",
      "        [ 1.2823],\n",
      "        [ 2.8247],\n",
      "        [ 7.5125],\n",
      "        [ 3.0989],\n",
      "        [ 1.4769],\n",
      "        [-1.4465],\n",
      "        [-2.6639],\n",
      "        [-2.5624],\n",
      "        [ 2.3448]])]\n",
      "---------------\n",
      "[tensor([[ 7.9078e-01,  1.0518e+00],\n",
      "        [ 8.0007e-04, -3.3465e-01],\n",
      "        [ 3.5844e-01, -3.5434e-01],\n",
      "        [-8.6244e-01,  1.5523e+00],\n",
      "        [ 5.9371e-01,  4.8346e-01],\n",
      "        [ 1.0108e-01,  2.1864e+00],\n",
      "        [ 3.7407e-01, -1.8206e+00],\n",
      "        [-1.7472e+00,  2.3259e-01],\n",
      "        [-6.8224e-02,  1.8469e+00],\n",
      "        [ 2.3749e-01,  1.5755e+00]]), tensor([[ 2.2159],\n",
      "        [ 5.3324],\n",
      "        [ 6.1145],\n",
      "        [-2.7984],\n",
      "        [ 3.7457],\n",
      "        [-3.0344],\n",
      "        [11.1408],\n",
      "        [-0.0955],\n",
      "        [-2.2070],\n",
      "        [-0.6870]])]\n",
      "---------------\n",
      "[tensor([[ 0.6800,  0.2830],\n",
      "        [ 1.7490,  1.7175],\n",
      "        [ 0.4383,  1.5445],\n",
      "        [-0.3949,  1.0954],\n",
      "        [-0.0884,  1.2307],\n",
      "        [-0.5723, -1.7760],\n",
      "        [-2.3321,  0.6105],\n",
      "        [ 1.6779,  0.0063],\n",
      "        [ 1.0357, -0.1390],\n",
      "        [ 0.3264, -1.1721]]), tensor([[ 4.5951],\n",
      "        [ 1.8628],\n",
      "        [-0.1804],\n",
      "        [-0.3135],\n",
      "        [-0.1482],\n",
      "        [ 9.0945],\n",
      "        [-2.5359],\n",
      "        [ 7.5376],\n",
      "        [ 6.7495],\n",
      "        [ 8.8286]])]\n",
      "---------------\n",
      "[tensor([[-1.1585, -0.1405],\n",
      "        [-1.6499,  0.6134],\n",
      "        [-0.6829,  0.2021],\n",
      "        [ 0.3376, -0.7335],\n",
      "        [ 0.2119, -0.3285],\n",
      "        [-1.1911,  1.5052],\n",
      "        [ 0.5324,  0.1952],\n",
      "        [-0.2036, -1.2365],\n",
      "        [ 0.3393,  1.2140],\n",
      "        [-0.2000,  0.5611]]), tensor([[ 2.3636],\n",
      "        [-1.1820],\n",
      "        [ 2.1576],\n",
      "        [ 7.3642],\n",
      "        [ 5.7311],\n",
      "        [-3.3003],\n",
      "        [ 4.6000],\n",
      "        [ 7.9936],\n",
      "        [ 0.7448],\n",
      "        [ 1.9053]])]\n",
      "---------------\n",
      "[tensor([[-1.8443,  0.1616],\n",
      "        [-0.6391,  0.3108],\n",
      "        [-0.2924, -0.6527],\n",
      "        [ 1.2279, -0.6301],\n",
      "        [-1.7162, -2.1999],\n",
      "        [ 0.7916, -1.1338],\n",
      "        [-0.1893,  1.0579],\n",
      "        [-0.2379, -0.9943],\n",
      "        [ 0.1551,  0.9174],\n",
      "        [ 1.9818,  0.9062]]), tensor([[-0.0541],\n",
      "        [ 1.8519],\n",
      "        [ 5.8510],\n",
      "        [ 8.8074],\n",
      "        [ 8.2390],\n",
      "        [ 9.6404],\n",
      "        [ 0.2216],\n",
      "        [ 7.1124],\n",
      "        [ 1.4031],\n",
      "        [ 5.0932]])]\n",
      "---------------\n",
      "[tensor([[ 0.8555,  0.4706],\n",
      "        [ 2.1157, -0.6399],\n",
      "        [ 0.6497, -1.4075],\n",
      "        [-1.1132,  0.2378],\n",
      "        [ 0.4938, -0.6274],\n",
      "        [ 0.9691,  0.2852],\n",
      "        [ 0.7572,  0.2782],\n",
      "        [ 1.4784,  0.3054],\n",
      "        [ 0.6702,  0.5997],\n",
      "        [-0.3613, -0.5626]]), tensor([[ 4.2942],\n",
      "        [10.6088],\n",
      "        [10.3032],\n",
      "        [ 1.1721],\n",
      "        [ 7.3219],\n",
      "        [ 5.1652],\n",
      "        [ 4.7809],\n",
      "        [ 6.1351],\n",
      "        [ 3.5106],\n",
      "        [ 5.3793]])]\n",
      "---------------\n",
      "[tensor([[ 1.0187,  1.2658],\n",
      "        [-1.1169,  1.0539],\n",
      "        [ 0.8802, -0.2358],\n",
      "        [ 0.1105, -1.8170],\n",
      "        [-0.5923, -2.1822],\n",
      "        [ 0.4690,  1.0277],\n",
      "        [ 0.3083, -1.1686],\n",
      "        [ 0.3260,  0.1233],\n",
      "        [-0.0756,  0.3660],\n",
      "        [ 0.1264,  0.1030]]), tensor([[ 1.9201],\n",
      "        [-1.6093],\n",
      "        [ 6.7691],\n",
      "        [10.5848],\n",
      "        [10.4313],\n",
      "        [ 1.6459],\n",
      "        [ 8.7659],\n",
      "        [ 4.4473],\n",
      "        [ 2.7904],\n",
      "        [ 4.1278]])]\n",
      "---------------\n",
      "[tensor([[ 0.2113,  0.4327],\n",
      "        [ 0.3200, -1.3266],\n",
      "        [-1.1834,  0.1885],\n",
      "        [-0.6687,  1.5666],\n",
      "        [-0.5990, -1.6420],\n",
      "        [ 0.4623, -1.1857],\n",
      "        [ 0.2524, -1.8362],\n",
      "        [-0.6395, -0.6204],\n",
      "        [-1.2677,  0.5480],\n",
      "        [-2.2653, -0.6398]]), tensor([[ 3.1442],\n",
      "        [ 9.3484],\n",
      "        [ 1.1783],\n",
      "        [-2.4605],\n",
      "        [ 8.5720],\n",
      "        [ 9.1680],\n",
      "        [10.9374],\n",
      "        [ 5.0233],\n",
      "        [-0.1862],\n",
      "        [ 1.8504]])]\n",
      "---------------\n",
      "[tensor([[-0.3102, -0.3417],\n",
      "        [-0.9003,  1.3565],\n",
      "        [ 1.3557,  0.2637],\n",
      "        [ 0.4720, -0.4709],\n",
      "        [-0.8062,  1.8243],\n",
      "        [-1.2749,  0.7752],\n",
      "        [-0.9648,  1.1984],\n",
      "        [ 1.3158, -1.5258],\n",
      "        [-0.4226, -0.7476],\n",
      "        [ 1.4516, -0.9275]]), tensor([[ 4.7549],\n",
      "        [-2.2027],\n",
      "        [ 6.0075],\n",
      "        [ 6.7482],\n",
      "        [-3.6169],\n",
      "        [-0.9680],\n",
      "        [-1.8182],\n",
      "        [12.0268],\n",
      "        [ 5.8930],\n",
      "        [10.2668]])]\n",
      "---------------\n",
      "[tensor([[ 0.4775,  1.9332],\n",
      "        [ 1.1998, -0.4462],\n",
      "        [ 0.5213, -0.7074],\n",
      "        [-0.1872, -1.9804],\n",
      "        [ 0.0743, -1.0759],\n",
      "        [-1.0574,  0.4850],\n",
      "        [-0.8712, -0.1045],\n",
      "        [-0.5660, -0.2456],\n",
      "        [-1.2464,  0.0243],\n",
      "        [-0.1442,  1.3776]]), tensor([[-1.4240],\n",
      "        [ 8.1098],\n",
      "        [ 7.6577],\n",
      "        [10.5646],\n",
      "        [ 7.9924],\n",
      "        [ 0.4312],\n",
      "        [ 2.8142],\n",
      "        [ 3.8921],\n",
      "        [ 1.6208],\n",
      "        [-0.7764]])]\n",
      "---------------\n",
      "[tensor([[-0.4617, -1.1629],\n",
      "        [ 0.2262, -2.3626],\n",
      "        [ 0.0737,  0.7652],\n",
      "        [-0.3143,  0.2470],\n",
      "        [-1.6037, -0.9201],\n",
      "        [-1.4316,  1.2978],\n",
      "        [-0.2124, -1.4979],\n",
      "        [-1.3318,  1.7210],\n",
      "        [ 1.2265,  1.3153],\n",
      "        [ 1.5694,  0.1060]]), tensor([[ 7.2452],\n",
      "        [12.7046],\n",
      "        [ 1.7514],\n",
      "        [ 2.7338],\n",
      "        [ 4.1277],\n",
      "        [-3.0720],\n",
      "        [ 8.8473],\n",
      "        [-4.3317],\n",
      "        [ 2.1671],\n",
      "        [ 6.9761]])]\n",
      "---------------\n",
      "[tensor([[-0.7355,  0.5261],\n",
      "        [-0.0567, -1.5883],\n",
      "        [ 1.2686,  0.2398],\n",
      "        [-0.7811, -1.1058],\n",
      "        [-0.4232, -0.0383],\n",
      "        [ 1.2388,  0.0243],\n",
      "        [ 1.0754,  1.6381],\n",
      "        [-1.9819, -0.0348],\n",
      "        [ 2.3325, -1.0843],\n",
      "        [-0.1981,  0.4035]]), tensor([[ 0.9480],\n",
      "        [ 9.4790],\n",
      "        [ 5.9134],\n",
      "        [ 6.3901],\n",
      "        [ 3.4875],\n",
      "        [ 6.5910],\n",
      "        [ 0.7571],\n",
      "        [ 0.3549],\n",
      "        [12.5601],\n",
      "        [ 2.4374]])]\n",
      "---------------\n",
      "[tensor([[ 0.2655, -0.0042],\n",
      "        [-1.4056, -2.0780],\n",
      "        [ 0.3559, -1.5580],\n",
      "        [-0.4124, -0.3185],\n",
      "        [ 0.9204, -1.1198],\n",
      "        [ 0.0386, -0.9444],\n",
      "        [-0.7420,  1.0338],\n",
      "        [-0.1673,  0.4467],\n",
      "        [ 2.1071,  0.8295],\n",
      "        [ 0.4630, -0.1289]]), tensor([[ 4.7377],\n",
      "        [ 8.4622],\n",
      "        [10.2028],\n",
      "        [ 4.4602],\n",
      "        [ 9.8480],\n",
      "        [ 7.4714],\n",
      "        [-0.7914],\n",
      "        [ 2.3437],\n",
      "        [ 5.5896],\n",
      "        [ 5.5592]])]\n",
      "---------------\n",
      "[tensor([[-0.9272, -0.0649],\n",
      "        [-0.5548, -0.7085],\n",
      "        [-0.1539, -1.7017],\n",
      "        [ 0.4819, -1.6164],\n",
      "        [ 0.2984,  0.2435],\n",
      "        [ 0.5824, -0.9771],\n",
      "        [-0.5550,  0.1742],\n",
      "        [ 0.0743,  0.5483],\n",
      "        [-0.9872,  1.5307],\n",
      "        [ 0.6804, -0.9222]]), tensor([[ 2.5685],\n",
      "        [ 5.4778],\n",
      "        [ 9.6603],\n",
      "        [10.6697],\n",
      "        [ 3.9781],\n",
      "        [ 8.6820],\n",
      "        [ 2.5001],\n",
      "        [ 2.4888],\n",
      "        [-2.9772],\n",
      "        [ 8.6975]])]\n",
      "---------------\n",
      "[tensor([[-0.0737,  1.7927],\n",
      "        [-0.0882,  0.2087],\n",
      "        [-0.3566,  0.5836],\n",
      "        [-0.2270, -1.2810],\n",
      "        [ 1.3980,  1.3352],\n",
      "        [ 1.7461,  0.7475],\n",
      "        [-0.8391, -0.5592],\n",
      "        [-1.3533,  0.6113],\n",
      "        [-0.1544, -0.3311],\n",
      "        [-1.1098,  0.6130]]), tensor([[-2.0447],\n",
      "        [ 3.3161],\n",
      "        [ 1.5185],\n",
      "        [ 8.0979],\n",
      "        [ 2.4631],\n",
      "        [ 5.1471],\n",
      "        [ 4.4334],\n",
      "        [-0.5941],\n",
      "        [ 5.0288],\n",
      "        [-0.0974]])]\n",
      "---------------\n",
      "[tensor([[ 2.2009, -0.5014],\n",
      "        [-0.4659, -0.1138],\n",
      "        [-0.4529, -1.5924],\n",
      "        [-0.3837,  0.0248],\n",
      "        [ 0.2415,  1.2391],\n",
      "        [-0.0214, -1.5999],\n",
      "        [ 0.2816, -1.2034],\n",
      "        [ 0.7217,  1.3703],\n",
      "        [-0.3992, -0.8716],\n",
      "        [ 0.0627, -1.0918]]), tensor([[10.3168],\n",
      "        [ 3.6588],\n",
      "        [ 8.6941],\n",
      "        [ 3.3402],\n",
      "        [ 0.4595],\n",
      "        [ 9.5856],\n",
      "        [ 8.8523],\n",
      "        [ 0.9755],\n",
      "        [ 6.3749],\n",
      "        [ 8.0440]])]\n",
      "---------------\n",
      "[tensor([[ 1.0539,  1.3477],\n",
      "        [-0.6892,  0.1859],\n",
      "        [ 0.1465, -1.8683],\n",
      "        [ 1.3401,  0.1484],\n",
      "        [-0.2862, -1.1235],\n",
      "        [-0.1744, -0.0861],\n",
      "        [-0.6901,  1.6474],\n",
      "        [-0.8517,  0.1487],\n",
      "        [ 0.0354, -0.3046],\n",
      "        [ 1.2722,  0.4804]]), tensor([[ 1.7353],\n",
      "        [ 2.1833],\n",
      "        [10.8737],\n",
      "        [ 6.3772],\n",
      "        [ 7.4318],\n",
      "        [ 4.1483],\n",
      "        [-2.7777],\n",
      "        [ 2.0011],\n",
      "        [ 5.3137],\n",
      "        [ 5.1250]])]\n",
      "---------------\n",
      "[tensor([[ 0.1814,  0.3708],\n",
      "        [-0.0207,  1.5191],\n",
      "        [ 1.0452, -1.2666],\n",
      "        [ 0.4872, -1.2698],\n",
      "        [ 0.5881,  0.6296],\n",
      "        [-0.2246, -2.2448],\n",
      "        [ 0.0790, -0.2016],\n",
      "        [-1.3122, -0.7235],\n",
      "        [-1.7339, -0.4880],\n",
      "        [ 0.9167, -0.4673]]), tensor([[ 3.2947],\n",
      "        [-1.0111],\n",
      "        [10.5852],\n",
      "        [ 9.5068],\n",
      "        [ 3.2417],\n",
      "        [11.3853],\n",
      "        [ 5.0214],\n",
      "        [ 4.0421],\n",
      "        [ 2.3849],\n",
      "        [ 7.6304]])]\n",
      "---------------\n",
      "[tensor([[-0.5003, -1.1413],\n",
      "        [ 1.3517,  0.3330],\n",
      "        [-0.7607,  0.5833],\n",
      "        [ 0.5129,  0.5538],\n",
      "        [ 1.3154,  0.2516],\n",
      "        [-0.0368,  0.6336],\n",
      "        [-0.6476,  0.3338],\n",
      "        [ 0.9032, -0.2481],\n",
      "        [-1.1838, -0.7463],\n",
      "        [-0.5422, -1.2474]]), tensor([[7.0811],\n",
      "        [5.7726],\n",
      "        [0.6850],\n",
      "        [3.3338],\n",
      "        [5.9609],\n",
      "        [1.9589],\n",
      "        [1.7743],\n",
      "        [6.8343],\n",
      "        [4.3790],\n",
      "        [7.3773]])]\n",
      "---------------\n",
      "[tensor([[ 0.1542,  0.3898],\n",
      "        [ 0.2319, -1.9223],\n",
      "        [ 0.7550,  0.3268],\n",
      "        [-2.1369,  0.5364],\n",
      "        [-0.9856, -1.4431],\n",
      "        [-0.7952, -0.5428],\n",
      "        [-0.8110,  1.1326],\n",
      "        [ 0.9820, -1.7504],\n",
      "        [-0.1491,  2.4081],\n",
      "        [-0.2636,  1.9860]]), tensor([[ 3.1661],\n",
      "        [11.2039],\n",
      "        [ 4.5984],\n",
      "        [-1.8837],\n",
      "        [ 7.1332],\n",
      "        [ 4.4573],\n",
      "        [-1.2654],\n",
      "        [12.1147],\n",
      "        [-4.2996],\n",
      "        [-3.0713]])]\n",
      "---------------\n",
      "[tensor([[ 0.3240,  0.2338],\n",
      "        [-0.9527,  0.9924],\n",
      "        [-0.6856,  1.0843],\n",
      "        [ 0.8684,  0.4684],\n",
      "        [ 0.7128,  1.3657],\n",
      "        [-0.0922, -0.5466],\n",
      "        [-1.8490,  1.7202],\n",
      "        [ 0.6049,  0.7432],\n",
      "        [ 0.3351, -0.3396],\n",
      "        [-0.5760, -1.2841]]), tensor([[ 4.0475],\n",
      "        [-1.0802],\n",
      "        [-0.8660],\n",
      "        [ 4.3466],\n",
      "        [ 0.9759],\n",
      "        [ 5.8594],\n",
      "        [-5.3435],\n",
      "        [ 2.8773],\n",
      "        [ 6.0323],\n",
      "        [ 7.4121]])]\n",
      "---------------\n",
      "[tensor([[-1.0765,  1.0014],\n",
      "        [-0.2164, -0.0505],\n",
      "        [ 0.1588,  1.7380],\n",
      "        [-0.2936, -0.5040],\n",
      "        [-0.1266, -0.7178],\n",
      "        [ 0.1272,  0.2359],\n",
      "        [-0.7794, -2.2008],\n",
      "        [-0.7790, -0.0543],\n",
      "        [ 2.0020,  0.8851],\n",
      "        [ 1.2443,  0.7072]]), tensor([[-1.3624],\n",
      "        [ 3.9458],\n",
      "        [-1.3936],\n",
      "        [ 5.3458],\n",
      "        [ 6.3899],\n",
      "        [ 3.6457],\n",
      "        [10.1142],\n",
      "        [ 2.8319],\n",
      "        [ 5.1948],\n",
      "        [ 4.2978]])]\n",
      "---------------\n",
      "[tensor([[-0.9009, -1.8035],\n",
      "        [ 0.1189,  0.1712],\n",
      "        [-0.4168, -0.8577],\n",
      "        [-0.1354,  1.6193],\n",
      "        [-0.6942, -0.7490],\n",
      "        [-1.1395,  0.9496],\n",
      "        [-0.4574, -1.1842],\n",
      "        [ 0.7942, -1.7436],\n",
      "        [-1.3150, -0.3605],\n",
      "        [-1.7510,  1.7770]]), tensor([[ 8.5266],\n",
      "        [ 3.8390],\n",
      "        [ 6.2736],\n",
      "        [-1.5776],\n",
      "        [ 5.3486],\n",
      "        [-1.2913],\n",
      "        [ 7.3073],\n",
      "        [11.7170],\n",
      "        [ 2.7916],\n",
      "        [-5.3352]])]\n",
      "---------------\n",
      "[tensor([[ 1.4375, -0.1276],\n",
      "        [ 0.4920, -0.2167],\n",
      "        [-2.1146,  0.4972],\n",
      "        [-0.6212,  0.9581],\n",
      "        [-0.5707, -0.3181],\n",
      "        [-0.1289,  1.3159],\n",
      "        [ 0.1404, -0.7049],\n",
      "        [ 2.1876, -0.3413],\n",
      "        [-0.4320, -1.2122],\n",
      "        [-0.0939, -1.2024]]), tensor([[ 7.5063],\n",
      "        [ 5.9183],\n",
      "        [-1.7237],\n",
      "        [-0.3026],\n",
      "        [ 4.1587],\n",
      "        [-0.5113],\n",
      "        [ 6.8858],\n",
      "        [ 9.7320],\n",
      "        [ 7.4678],\n",
      "        [ 8.0931]])]\n",
      "---------------\n",
      "[tensor([[-2.9204e-01,  2.3168e-03],\n",
      "        [ 1.4549e+00, -3.3277e-01],\n",
      "        [-8.2296e-01, -1.0824e+00],\n",
      "        [ 1.5514e+00, -3.8086e-01],\n",
      "        [-9.6173e-01,  8.0466e-01],\n",
      "        [ 7.0790e-01,  2.5830e-01],\n",
      "        [-9.7469e-02,  4.9754e-01],\n",
      "        [-1.1485e+00,  2.9367e-01],\n",
      "        [ 6.9400e-01,  8.8110e-01],\n",
      "        [ 1.6898e-03, -1.9761e+00]]), tensor([[ 3.6208],\n",
      "        [ 8.2400],\n",
      "        [ 6.2219],\n",
      "        [ 8.6056],\n",
      "        [-0.4522],\n",
      "        [ 4.7372],\n",
      "        [ 2.3356],\n",
      "        [ 0.9021],\n",
      "        [ 2.6019],\n",
      "        [10.9272]])]\n",
      "---------------\n",
      "[tensor([[ 0.2708,  1.2813],\n",
      "        [-0.5185, -1.2123],\n",
      "        [-1.9764,  0.1881],\n",
      "        [-1.3514, -1.0145],\n",
      "        [-0.5365,  0.5846],\n",
      "        [ 1.6668, -2.3416],\n",
      "        [ 0.9899, -0.4060],\n",
      "        [-1.4193, -0.3907],\n",
      "        [ 0.0233, -0.6822],\n",
      "        [-0.0898, -0.9023]]), tensor([[ 0.3809],\n",
      "        [ 7.2730],\n",
      "        [-0.3889],\n",
      "        [ 4.9468],\n",
      "        [ 1.1288],\n",
      "        [15.4822],\n",
      "        [ 7.5551],\n",
      "        [ 2.7142],\n",
      "        [ 6.5457],\n",
      "        [ 7.0976]])]\n",
      "---------------\n",
      "[tensor([[-0.1997, -0.2983],\n",
      "        [ 1.0606, -1.1411],\n",
      "        [ 0.5452,  0.5848],\n",
      "        [ 0.4177, -0.5872],\n",
      "        [ 0.7834,  1.0408],\n",
      "        [-1.3485,  1.4816],\n",
      "        [-0.6538, -0.6131],\n",
      "        [-0.4590, -1.8905],\n",
      "        [-1.0885,  0.2757],\n",
      "        [-0.0336,  0.3320]]), tensor([[ 4.8046],\n",
      "        [10.2097],\n",
      "        [ 3.3068],\n",
      "        [ 7.0276],\n",
      "        [ 2.2255],\n",
      "        [-3.5507],\n",
      "        [ 4.9870],\n",
      "        [ 9.7048],\n",
      "        [ 1.0664],\n",
      "        [ 3.0161]])]\n",
      "---------------\n",
      "[tensor([[-0.2967, -2.7671],\n",
      "        [-2.4900, -2.2091],\n",
      "        [-2.2950, -0.8891],\n",
      "        [ 0.1216, -0.6488],\n",
      "        [-0.2002,  0.5310],\n",
      "        [-1.5380,  0.1095],\n",
      "        [ 1.2705, -0.1220],\n",
      "        [ 1.5504,  0.4656],\n",
      "        [-0.4240,  0.5809],\n",
      "        [-0.4095,  1.6987]]), tensor([[13.0212],\n",
      "        [ 6.7315],\n",
      "        [ 2.6062],\n",
      "        [ 6.6371],\n",
      "        [ 1.9994],\n",
      "        [ 0.7481],\n",
      "        [ 7.1763],\n",
      "        [ 5.7223],\n",
      "        [ 1.3624],\n",
      "        [-2.4007]])]\n",
      "---------------\n",
      "[tensor([[ 0.2843,  1.2978],\n",
      "        [-0.2350,  0.3849],\n",
      "        [ 1.1171, -1.8632],\n",
      "        [ 0.0109,  0.8485],\n",
      "        [-1.2842,  0.6967],\n",
      "        [ 1.2721, -0.1697],\n",
      "        [ 1.8553,  0.2065],\n",
      "        [-0.4230, -0.3628],\n",
      "        [ 1.1706, -1.2734],\n",
      "        [ 0.5056,  0.5777]]), tensor([[ 0.3678],\n",
      "        [ 2.4169],\n",
      "        [12.8017],\n",
      "        [ 1.3399],\n",
      "        [-0.7415],\n",
      "        [ 7.3203],\n",
      "        [ 7.2021],\n",
      "        [ 4.5830],\n",
      "        [10.9006],\n",
      "        [ 3.2562]])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l\n",
    "import torch.nn as nn\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "ture_b = 4.2\n",
    "feats, labels = d2l.synthetic_data(true_w, ture_b, 1000)\n",
    "print('----------')\n",
    "print(feats)\n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True): ## 注意这里的使用\n",
    "    \"\"\"构造一个Pytorch数据迭代器\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)   ## 以及这里的*：作用于可迭代对象\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "batch_size = 10\n",
    "data_iter = load_array((feats,labels), batch_size)\n",
    "\n",
    "for data in data_iter:\n",
    "    print('---------------')\n",
    "    print(data)\n",
    "\n",
    "    \n",
    "# next(iter(data_iter))    ## iter：生成迭代器\n",
    "\n",
    "# net = nn.Sequential(nn.Linear(2,1))\n",
    "\n",
    "# net[0].weight.data.normal_(0, 0.01)  ##初始化 单层网络因此可以直接索引\n",
    "# net[0].bias.data.fill_(0)\n",
    "\n",
    "# loss = nn.MSELoss()\n",
    "# trainer = torch.optim.SGD(net.parameters(), lr=0.03)\n",
    "\n",
    "# num_epochs = 3\n",
    "# for epoch in range(num_epochs):\n",
    "#     for X, y in data_iter:\n",
    "#         l = loss(net(X), y)\n",
    "#         trainer.zero_grad()\n",
    "#         l.backward()\n",
    "#         trainer.step()\n",
    "#     l = loss(net(feats), labels)\n",
    "#     print(f'epoch {epoch + 1}, loss {l:f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 梯度下降时，注意除以batch_size，避免由于这个参数导致的数值差异过大；或者让lr来除调节学习率\n",
    "- 合理初始化/Adam \n",
    "- batch_size：小则更利于收敛--->噪音，鲁棒\n",
    "  - 更新：batch中每一个样本对应参数求梯度求和取平均值更新\n",
    "- 一阶导向量，二阶导梯度/矩阵；  \n",
    "   - 统计模型与优化模型-->收敛速度快与泛化性等无关；saddle point\n",
    "- load可能存在内存爆掉；硬盘与内存，prefetch\n",
    "- SGD：本质原因：NPC，没有显示解，导数为0；batch逐一逼近"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 softmax回归+损失函数+图片分类数据集\n",
    "## softmax回归\n",
    "- 从回归到多类分类\n",
    "- 分类\n",
    "  - 均方损失\n",
    "    - 对类别一位有效编码\n",
    "    - 均方损失训练\n",
    "  - 无校验比例\n",
    "    $O_y - O_i >= \\Delta(y,i)$\n",
    "  - 校验比例\n",
    "     - 匹配概率，softmax，概率区别\n",
    "- softmax与交叉熵损失: 预测置信度\n",
    " $$l(\\textbf{y},\\hat{\\textbf{y}}) = -\\sum_{\\substack{i}}y_i\\log{\\hat{y}_i} = -\\log{\\hat{y}_y}$$\n",
    " \n",
    "## 损失函数\n",
    "损失函数，似然函数，导数\n",
    "- L2 Loss: \n",
    "- L1 Loss：梯度常数，权重更新稳定\n",
    "- Huber's Robust Loss\n",
    "$\\rightarrow$ 依据距离远近，函数、梯度形状\n",
    "\n",
    "## 图像分类数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fa9b1476f84f53a5774db26bdbf0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1b1ac3f44456>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtrans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;31m##-----这里 转化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m mnist_train = torchvision.datasets.MNIST(\n\u001b[1;32m---> 12\u001b[1;33m root=\"../data\", train=True, transform=trans, download=True)\n\u001b[0m\u001b[0;32m     13\u001b[0m mnist_test = torchvisionhvision.datasets.MNIST(\n\u001b[0;32m     14\u001b[0m root=\"../data\", train=False, transform=trans, download=True)\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    177\u001b[0m                         \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m                         \u001b[0mmd5\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmd5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m                     )\n\u001b[0;32m    181\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\torchvision\\datasets\\utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m     \u001b[0mdownload_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[0marchive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\torchvision\\datasets\\utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[1;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloading '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m             \u001b[0m_urlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mURLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# type: ignore[attr-defined]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'https'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\torchvision\\datasets\\utils.py\u001b[0m in \u001b[0;36m_urlretrieve\u001b[1;34m(url, filename, chunk_size)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"User-Agent\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUSER_AGENT\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\torchvision\\datasets\\utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"User-Agent\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUSER_AGENT\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m             \u001b[1;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### 这个代码块没有具体实现所以不能运行 不要运行不然报一堆错\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "import d2l.torch as d2l\n",
    "\n",
    "d2l.use_svg_display()    ## 使用svg， 据说图像更加清晰\n",
    "\"\"\"加载数据集\"\"\"\n",
    "trans = transforms.ToTensor()       ##-----这里 转化\n",
    "mnist_train = torchvision.datasets.MNIST(\n",
    "root=\"../data\", train=True, transform=trans, download=True)\n",
    "mnist_test = torchvisionhvision.datasets.MNIST(\n",
    "root=\"../data\", train=False, transform=trans, download=True)\n",
    "\n",
    "len(mnist_test),len(mnist_train)\n",
    "mnist_train[0][0].shape\n",
    "\n",
    "\"\"\"绘制\"\"\"\n",
    "def get_fashion_mnist_labels(labels):\n",
    "    \"\"\"返回Fashion-MNIST数据集的文本标签\"\"\"\n",
    "    text_labels = [\n",
    "        't-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "        'sandal', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]\n",
    "    \n",
    "def show_images(img, num_rows, num_cols, titles=None, scale=1.5):\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    _, axes = d2l.plt.subplot(num_rows, num_cols, figsize)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        if torch.is_tensor(img):\n",
    "            # 图片张量\n",
    "            ax.imshow(img.numpy())\n",
    "        else:\n",
    "            # PIL图片\n",
    "            ax.imshow(img)\n",
    "\n",
    "\"\"\"图像与标签\"\"\"\n",
    "X, y = next(iter(data.DataLoader(mnist_train, batch_size=18)))\n",
    "show_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels)   \n",
    "\n",
    "\"\"\"批量读取\"\"\"\n",
    "batch_size = 256\n",
    "\n",
    "def get_dataloder_workers():\n",
    "    return 4\n",
    "\n",
    "train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=get_dataloder_workers())#训练集随机\n",
    "timer = d2l.Timer()\n",
    "for X, y in train_iter:\n",
    "    continue\n",
    "f'{timer.stop():.2f} sec'              #  使用计时器什么的\n",
    "\n",
    "\"\"\"函数定义\"\"\"\n",
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    \"\"\"下载数据集并加载到内存中\"\"\"\n",
    "    trans = [transforms.ToTensor()]       # 注意transforms的使用，处理图像\n",
    "    if resize:                                    # 直到这里才第一次理解到transforms到底是在干啥，组合操作\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    \n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root='../data', train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root='../data', train=False, transform=trans, download=True)\n",
    "    \n",
    "    return(data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=get_dataloder_workers),\n",
    "          data.DataLoader(mnist_test, batch_size, shuffle=True, num_workers=get_dataloder_workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## softmax回归从零开始实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 这个也没有实现\n",
    "import torch\n",
    "import numpy as np\n",
    "from IPython import display \n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "\n",
    "num_inputs = 784    # 28*28\n",
    "num_outputs = 10\n",
    "\n",
    "\"\"\"初始化参数\"\"\"\n",
    "W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)\n",
    "b = torch.zeros(num_outputs, requires_grad=True)\n",
    "\n",
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    partition = X_exp.sum(1, keepdim=True)\n",
    "    return X_exp / partition    # 广播机制\n",
    "\n",
    "\"\"\"实现softmax回归\"\"\"\n",
    "def net(X):                     # 由于reshape感觉这个地方变得有点怪只能说\n",
    "    return softmax(torch.matmul(X.reshape(-1, W.shape[0]), W) + b)   # 好了我现在理解了，应该是：图片个数×784 (原先纠结于特征)\n",
    "\n",
    "\"\"\"实现交叉熵损失函数\"\"\"\n",
    "def cross_entropy(y_hat, y):\n",
    "    return -torch.log(y_hat[range(len(y_hat)), y])   ## 注意这个用法，很奇妙的\n",
    "\n",
    "\"\"\"计算预测正确的数量\"\"\"\n",
    "def accuracy(y_hat, y):\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis = 1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    ".  \n",
    "\"\"\"计算在指定数据集上模型的精度\"\"\"\n",
    "def evaluate_accuracy(net, data_iter):\n",
    "    if isinstance(net, torch.nn.Module):  # 这个东西是区别于model.train()和model.eval()的\n",
    "        # 将模型设置为评估模型\n",
    "        net.eval()  \n",
    "    # 正确预测数、预测总数\n",
    "    metric = Accumulator(2)      # 具体累加器实现，感觉挺好用的\n",
    "    for X, y in data_iter:\n",
    "        metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "class Accumulator:\n",
    "    def _init_(self, n):\n",
    "        self.data = [0.0] * n\n",
    "    \n",
    "    def add(self, *arg):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "    \n",
    "    def _getitem_(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    \n",
    "evaluate_accuracya(net, test_ite r)\n",
    "\n",
    "\"\"\"训练\"\"\"\n",
    "def train_epoch_ch3(net, train_iter, loss, update):  ## 这次代码中很多判断这种\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    metric = Accumulator(3)\n",
    "    for X, y in train_iter:\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        if isinstance(update, torch.optim.Optimizer):\n",
    "            update.zero_grad()\n",
    "            l.backward()\n",
    "            update.step()\n",
    "            metric.add(\n",
    "               float(l) * len(y), accuracy(y_hat, y),\n",
    "                y.size().numel()\n",
    "            )\n",
    "        else:\n",
    "            l.sum().backward()\n",
    "            update(X.shape[0])\n",
    "            metric.add(float(l.sum()), accuracy(y_hat, y), y.size().numel())\n",
    "    \n",
    "    return metric[0] / metric[2], metric[1] / metric[2]\n",
    "\n",
    "\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, update):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch_ch3(net, train_iter, loss, update)\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\n",
    "    \n",
    "    train_loss, train_acc = train_metrics\n",
    "\n",
    "\n",
    "lr = 0.1\n",
    "def update(batch_size):\n",
    "    return d2l.sgd([W, b], lr, batch_size)\n",
    "\n",
    "num_epochs = 10\n",
    "train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs,update)\n",
    "\n",
    "\"\"\"PS部分\"\"\"\n",
    "# sum求和注意keepdim=True，保持维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from d2l import torch as d2l\n",
    "\n",
    "a = torch.tensor([[1, 2, 3], [2, 3, 4]])\n",
    "# a.size().numel()\n",
    "#batch_size = 256\n",
    "#train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "\n",
    "# next(iter(train_iter))\n",
    "# image = torch.tensor(next(iter(train_iter)))\n",
    "\n",
    "# image = image.cpu().clone()\n",
    "# image = image.squeeze(0) # 压缩一维\n",
    "# image = transforms.ToPILImage(image) # 自动转换为0-255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## softmax回归的简洁实现\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n",
       "<svg height=\"180.65625pt\" version=\"1.1\" viewBox=\"0 0 238.965625 180.65625\" width=\"238.965625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       " <metadata>\r\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n",
       "   <cc:Work>\r\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n",
       "    <dc:date>2022-02-09T20:17:13.772281</dc:date>\r\n",
       "    <dc:format>image/svg+xml</dc:format>\r\n",
       "    <dc:creator>\r\n",
       "     <cc:Agent>\r\n",
       "      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\r\n",
       "     </cc:Agent>\r\n",
       "    </dc:creator>\r\n",
       "   </cc:Work>\r\n",
       "  </rdf:RDF>\r\n",
       " </metadata>\r\n",
       " <defs>\r\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n",
       " </defs>\r\n",
       " <g id=\"figure_1\">\r\n",
       "  <g id=\"patch_1\">\r\n",
       "   <path d=\"M 0 180.65625 \r\n",
       "L 238.965625 180.65625 \r\n",
       "L 238.965625 0 \r\n",
       "L 0 0 \r\n",
       "z\r\n",
       "\" style=\"fill:none;\"/>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_1\">\r\n",
       "   <g id=\"patch_2\">\r\n",
       "    <path d=\"M 30.103125 143.1 \r\n",
       "L 225.403125 143.1 \r\n",
       "L 225.403125 7.2 \r\n",
       "L 30.103125 7.2 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_1\">\r\n",
       "    <g id=\"xtick_1\">\r\n",
       "     <g id=\"line2d_1\">\r\n",
       "      <path clip-path=\"url(#p2e92b39dca)\" d=\"M 51.803125 143.1 \r\n",
       "L 51.803125 7.2 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_2\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 0 3.5 \r\n",
       "\" id=\"md9c5fe7a17\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.803125\" xlink:href=\"#md9c5fe7a17\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_1\">\r\n",
       "      <!-- 2 -->\r\n",
       "      <g transform=\"translate(48.621875 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 19.1875 8.296875 \r\n",
       "L 53.609375 8.296875 \r\n",
       "L 53.609375 0 \r\n",
       "L 7.328125 0 \r\n",
       "L 7.328125 8.296875 \r\n",
       "Q 12.9375 14.109375 22.625 23.890625 \r\n",
       "Q 32.328125 33.6875 34.8125 36.53125 \r\n",
       "Q 39.546875 41.84375 41.421875 45.53125 \r\n",
       "Q 43.3125 49.21875 43.3125 52.78125 \r\n",
       "Q 43.3125 58.59375 39.234375 62.25 \r\n",
       "Q 35.15625 65.921875 28.609375 65.921875 \r\n",
       "Q 23.96875 65.921875 18.8125 64.3125 \r\n",
       "Q 13.671875 62.703125 7.8125 59.421875 \r\n",
       "L 7.8125 69.390625 \r\n",
       "Q 13.765625 71.78125 18.9375 73 \r\n",
       "Q 24.125 74.21875 28.421875 74.21875 \r\n",
       "Q 39.75 74.21875 46.484375 68.546875 \r\n",
       "Q 53.21875 62.890625 53.21875 53.421875 \r\n",
       "Q 53.21875 48.921875 51.53125 44.890625 \r\n",
       "Q 49.859375 40.875 45.40625 35.40625 \r\n",
       "Q 44.1875 33.984375 37.640625 27.21875 \r\n",
       "Q 31.109375 20.453125 19.1875 8.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-50\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_2\">\r\n",
       "     <g id=\"line2d_3\">\r\n",
       "      <path clip-path=\"url(#p2e92b39dca)\" d=\"M 95.203125 143.1 \r\n",
       "L 95.203125 7.2 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_4\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"95.203125\" xlink:href=\"#md9c5fe7a17\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_2\">\r\n",
       "      <!-- 4 -->\r\n",
       "      <g transform=\"translate(92.021875 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 37.796875 64.3125 \r\n",
       "L 12.890625 25.390625 \r\n",
       "L 37.796875 25.390625 \r\n",
       "z\r\n",
       "M 35.203125 72.90625 \r\n",
       "L 47.609375 72.90625 \r\n",
       "L 47.609375 25.390625 \r\n",
       "L 58.015625 25.390625 \r\n",
       "L 58.015625 17.1875 \r\n",
       "L 47.609375 17.1875 \r\n",
       "L 47.609375 0 \r\n",
       "L 37.796875 0 \r\n",
       "L 37.796875 17.1875 \r\n",
       "L 4.890625 17.1875 \r\n",
       "L 4.890625 26.703125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-52\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_3\">\r\n",
       "     <g id=\"line2d_5\">\r\n",
       "      <path clip-path=\"url(#p2e92b39dca)\" d=\"M 138.603125 143.1 \r\n",
       "L 138.603125 7.2 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_6\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"138.603125\" xlink:href=\"#md9c5fe7a17\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_3\">\r\n",
       "      <!-- 6 -->\r\n",
       "      <g transform=\"translate(135.421875 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 33.015625 40.375 \r\n",
       "Q 26.375 40.375 22.484375 35.828125 \r\n",
       "Q 18.609375 31.296875 18.609375 23.390625 \r\n",
       "Q 18.609375 15.53125 22.484375 10.953125 \r\n",
       "Q 26.375 6.390625 33.015625 6.390625 \r\n",
       "Q 39.65625 6.390625 43.53125 10.953125 \r\n",
       "Q 47.40625 15.53125 47.40625 23.390625 \r\n",
       "Q 47.40625 31.296875 43.53125 35.828125 \r\n",
       "Q 39.65625 40.375 33.015625 40.375 \r\n",
       "z\r\n",
       "M 52.59375 71.296875 \r\n",
       "L 52.59375 62.3125 \r\n",
       "Q 48.875 64.0625 45.09375 64.984375 \r\n",
       "Q 41.3125 65.921875 37.59375 65.921875 \r\n",
       "Q 27.828125 65.921875 22.671875 59.328125 \r\n",
       "Q 17.53125 52.734375 16.796875 39.40625 \r\n",
       "Q 19.671875 43.65625 24.015625 45.921875 \r\n",
       "Q 28.375 48.1875 33.59375 48.1875 \r\n",
       "Q 44.578125 48.1875 50.953125 41.515625 \r\n",
       "Q 57.328125 34.859375 57.328125 23.390625 \r\n",
       "Q 57.328125 12.15625 50.6875 5.359375 \r\n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \r\n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \r\n",
       "Q 6.984375 17.96875 6.984375 36.375 \r\n",
       "Q 6.984375 53.65625 15.1875 63.9375 \r\n",
       "Q 23.390625 74.21875 37.203125 74.21875 \r\n",
       "Q 40.921875 74.21875 44.703125 73.484375 \r\n",
       "Q 48.484375 72.75 52.59375 71.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-54\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_4\">\r\n",
       "     <g id=\"line2d_7\">\r\n",
       "      <path clip-path=\"url(#p2e92b39dca)\" d=\"M 182.003125 143.1 \r\n",
       "L 182.003125 7.2 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_8\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"182.003125\" xlink:href=\"#md9c5fe7a17\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_4\">\r\n",
       "      <!-- 8 -->\r\n",
       "      <g transform=\"translate(178.821875 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 31.78125 34.625 \r\n",
       "Q 24.75 34.625 20.71875 30.859375 \r\n",
       "Q 16.703125 27.09375 16.703125 20.515625 \r\n",
       "Q 16.703125 13.921875 20.71875 10.15625 \r\n",
       "Q 24.75 6.390625 31.78125 6.390625 \r\n",
       "Q 38.8125 6.390625 42.859375 10.171875 \r\n",
       "Q 46.921875 13.96875 46.921875 20.515625 \r\n",
       "Q 46.921875 27.09375 42.890625 30.859375 \r\n",
       "Q 38.875 34.625 31.78125 34.625 \r\n",
       "z\r\n",
       "M 21.921875 38.8125 \r\n",
       "Q 15.578125 40.375 12.03125 44.71875 \r\n",
       "Q 8.5 49.078125 8.5 55.328125 \r\n",
       "Q 8.5 64.0625 14.71875 69.140625 \r\n",
       "Q 20.953125 74.21875 31.78125 74.21875 \r\n",
       "Q 42.671875 74.21875 48.875 69.140625 \r\n",
       "Q 55.078125 64.0625 55.078125 55.328125 \r\n",
       "Q 55.078125 49.078125 51.53125 44.71875 \r\n",
       "Q 48 40.375 41.703125 38.8125 \r\n",
       "Q 48.828125 37.15625 52.796875 32.3125 \r\n",
       "Q 56.78125 27.484375 56.78125 20.515625 \r\n",
       "Q 56.78125 9.90625 50.3125 4.234375 \r\n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \r\n",
       "Q 19.734375 -1.421875 13.25 4.234375 \r\n",
       "Q 6.78125 9.90625 6.78125 20.515625 \r\n",
       "Q 6.78125 27.484375 10.78125 32.3125 \r\n",
       "Q 14.796875 37.15625 21.921875 38.8125 \r\n",
       "z\r\n",
       "M 18.3125 54.390625 \r\n",
       "Q 18.3125 48.734375 21.84375 45.5625 \r\n",
       "Q 25.390625 42.390625 31.78125 42.390625 \r\n",
       "Q 38.140625 42.390625 41.71875 45.5625 \r\n",
       "Q 45.3125 48.734375 45.3125 54.390625 \r\n",
       "Q 45.3125 60.0625 41.71875 63.234375 \r\n",
       "Q 38.140625 66.40625 31.78125 66.40625 \r\n",
       "Q 25.390625 66.40625 21.84375 63.234375 \r\n",
       "Q 18.3125 60.0625 18.3125 54.390625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-56\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_5\">\r\n",
       "     <g id=\"line2d_9\">\r\n",
       "      <path clip-path=\"url(#p2e92b39dca)\" d=\"M 225.403125 143.1 \r\n",
       "L 225.403125 7.2 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_10\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"225.403125\" xlink:href=\"#md9c5fe7a17\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_5\">\r\n",
       "      <!-- 10 -->\r\n",
       "      <g transform=\"translate(219.040625 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 12.40625 8.296875 \r\n",
       "L 28.515625 8.296875 \r\n",
       "L 28.515625 63.921875 \r\n",
       "L 10.984375 60.40625 \r\n",
       "L 10.984375 69.390625 \r\n",
       "L 28.421875 72.90625 \r\n",
       "L 38.28125 72.90625 \r\n",
       "L 38.28125 8.296875 \r\n",
       "L 54.390625 8.296875 \r\n",
       "L 54.390625 0 \r\n",
       "L 12.40625 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-49\"/>\r\n",
       "        <path d=\"M 31.78125 66.40625 \r\n",
       "Q 24.171875 66.40625 20.328125 58.90625 \r\n",
       "Q 16.5 51.421875 16.5 36.375 \r\n",
       "Q 16.5 21.390625 20.328125 13.890625 \r\n",
       "Q 24.171875 6.390625 31.78125 6.390625 \r\n",
       "Q 39.453125 6.390625 43.28125 13.890625 \r\n",
       "Q 47.125 21.390625 47.125 36.375 \r\n",
       "Q 47.125 51.421875 43.28125 58.90625 \r\n",
       "Q 39.453125 66.40625 31.78125 66.40625 \r\n",
       "z\r\n",
       "M 31.78125 74.21875 \r\n",
       "Q 44.046875 74.21875 50.515625 64.515625 \r\n",
       "Q 56.984375 54.828125 56.984375 36.375 \r\n",
       "Q 56.984375 17.96875 50.515625 8.265625 \r\n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \r\n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \r\n",
       "Q 6.59375 17.96875 6.59375 36.375 \r\n",
       "Q 6.59375 54.828125 13.0625 64.515625 \r\n",
       "Q 19.53125 74.21875 31.78125 74.21875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-48\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_6\">\r\n",
       "     <!-- epoch -->\r\n",
       "     <g transform=\"translate(112.525 171.376563)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 56.203125 29.59375 \r\n",
       "L 56.203125 25.203125 \r\n",
       "L 14.890625 25.203125 \r\n",
       "Q 15.484375 15.921875 20.484375 11.0625 \r\n",
       "Q 25.484375 6.203125 34.421875 6.203125 \r\n",
       "Q 39.59375 6.203125 44.453125 7.46875 \r\n",
       "Q 49.3125 8.734375 54.109375 11.28125 \r\n",
       "L 54.109375 2.78125 \r\n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \r\n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \r\n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \r\n",
       "Q 5.515625 13.8125 5.515625 26.8125 \r\n",
       "Q 5.515625 40.234375 12.765625 48.109375 \r\n",
       "Q 20.015625 56 32.328125 56 \r\n",
       "Q 43.359375 56 49.78125 48.890625 \r\n",
       "Q 56.203125 41.796875 56.203125 29.59375 \r\n",
       "z\r\n",
       "M 47.21875 32.234375 \r\n",
       "Q 47.125 39.59375 43.09375 43.984375 \r\n",
       "Q 39.0625 48.390625 32.421875 48.390625 \r\n",
       "Q 24.90625 48.390625 20.390625 44.140625 \r\n",
       "Q 15.875 39.890625 15.1875 32.171875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-101\"/>\r\n",
       "       <path d=\"M 18.109375 8.203125 \r\n",
       "L 18.109375 -20.796875 \r\n",
       "L 9.078125 -20.796875 \r\n",
       "L 9.078125 54.6875 \r\n",
       "L 18.109375 54.6875 \r\n",
       "L 18.109375 46.390625 \r\n",
       "Q 20.953125 51.265625 25.265625 53.625 \r\n",
       "Q 29.59375 56 35.59375 56 \r\n",
       "Q 45.5625 56 51.78125 48.09375 \r\n",
       "Q 58.015625 40.1875 58.015625 27.296875 \r\n",
       "Q 58.015625 14.40625 51.78125 6.484375 \r\n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \r\n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \r\n",
       "Q 20.953125 3.328125 18.109375 8.203125 \r\n",
       "z\r\n",
       "M 48.6875 27.296875 \r\n",
       "Q 48.6875 37.203125 44.609375 42.84375 \r\n",
       "Q 40.53125 48.484375 33.40625 48.484375 \r\n",
       "Q 26.265625 48.484375 22.1875 42.84375 \r\n",
       "Q 18.109375 37.203125 18.109375 27.296875 \r\n",
       "Q 18.109375 17.390625 22.1875 11.75 \r\n",
       "Q 26.265625 6.109375 33.40625 6.109375 \r\n",
       "Q 40.53125 6.109375 44.609375 11.75 \r\n",
       "Q 48.6875 17.390625 48.6875 27.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-112\"/>\r\n",
       "       <path d=\"M 30.609375 48.390625 \r\n",
       "Q 23.390625 48.390625 19.1875 42.75 \r\n",
       "Q 14.984375 37.109375 14.984375 27.296875 \r\n",
       "Q 14.984375 17.484375 19.15625 11.84375 \r\n",
       "Q 23.34375 6.203125 30.609375 6.203125 \r\n",
       "Q 37.796875 6.203125 41.984375 11.859375 \r\n",
       "Q 46.1875 17.53125 46.1875 27.296875 \r\n",
       "Q 46.1875 37.015625 41.984375 42.703125 \r\n",
       "Q 37.796875 48.390625 30.609375 48.390625 \r\n",
       "z\r\n",
       "M 30.609375 56 \r\n",
       "Q 42.328125 56 49.015625 48.375 \r\n",
       "Q 55.71875 40.765625 55.71875 27.296875 \r\n",
       "Q 55.71875 13.875 49.015625 6.21875 \r\n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \r\n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \r\n",
       "Q 5.515625 13.875 5.515625 27.296875 \r\n",
       "Q 5.515625 40.765625 12.171875 48.375 \r\n",
       "Q 18.84375 56 30.609375 56 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-111\"/>\r\n",
       "       <path d=\"M 48.78125 52.59375 \r\n",
       "L 48.78125 44.1875 \r\n",
       "Q 44.96875 46.296875 41.140625 47.34375 \r\n",
       "Q 37.3125 48.390625 33.40625 48.390625 \r\n",
       "Q 24.65625 48.390625 19.8125 42.84375 \r\n",
       "Q 14.984375 37.3125 14.984375 27.296875 \r\n",
       "Q 14.984375 17.28125 19.8125 11.734375 \r\n",
       "Q 24.65625 6.203125 33.40625 6.203125 \r\n",
       "Q 37.3125 6.203125 41.140625 7.25 \r\n",
       "Q 44.96875 8.296875 48.78125 10.40625 \r\n",
       "L 48.78125 2.09375 \r\n",
       "Q 45.015625 0.34375 40.984375 -0.53125 \r\n",
       "Q 36.96875 -1.421875 32.421875 -1.421875 \r\n",
       "Q 20.0625 -1.421875 12.78125 6.34375 \r\n",
       "Q 5.515625 14.109375 5.515625 27.296875 \r\n",
       "Q 5.515625 40.671875 12.859375 48.328125 \r\n",
       "Q 20.21875 56 33.015625 56 \r\n",
       "Q 37.15625 56 41.109375 55.140625 \r\n",
       "Q 45.0625 54.296875 48.78125 52.59375 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-99\"/>\r\n",
       "       <path d=\"M 54.890625 33.015625 \r\n",
       "L 54.890625 0 \r\n",
       "L 45.90625 0 \r\n",
       "L 45.90625 32.71875 \r\n",
       "Q 45.90625 40.484375 42.875 44.328125 \r\n",
       "Q 39.84375 48.1875 33.796875 48.1875 \r\n",
       "Q 26.515625 48.1875 22.3125 43.546875 \r\n",
       "Q 18.109375 38.921875 18.109375 30.90625 \r\n",
       "L 18.109375 0 \r\n",
       "L 9.078125 0 \r\n",
       "L 9.078125 75.984375 \r\n",
       "L 18.109375 75.984375 \r\n",
       "L 18.109375 46.1875 \r\n",
       "Q 21.34375 51.125 25.703125 53.5625 \r\n",
       "Q 30.078125 56 35.796875 56 \r\n",
       "Q 45.21875 56 50.046875 50.171875 \r\n",
       "Q 54.890625 44.34375 54.890625 33.015625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-104\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-101\"/>\r\n",
       "      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\r\n",
       "      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\r\n",
       "      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\r\n",
       "      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_2\">\r\n",
       "    <g id=\"ytick_1\">\r\n",
       "     <g id=\"line2d_11\">\r\n",
       "      <path clip-path=\"url(#p2e92b39dca)\" d=\"M 30.103125 120.45 \r\n",
       "L 225.403125 120.45 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_12\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L -3.5 0 \r\n",
       "\" id=\"m15526e4f85\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m15526e4f85\" y=\"120.45\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_7\">\r\n",
       "      <!-- 0.4 -->\r\n",
       "      <g transform=\"translate(7.2 124.249219)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 10.6875 12.40625 \r\n",
       "L 21 12.40625 \r\n",
       "L 21 0 \r\n",
       "L 10.6875 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-46\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_2\">\r\n",
       "     <g id=\"line2d_13\">\r\n",
       "      <path clip-path=\"url(#p2e92b39dca)\" d=\"M 30.103125 75.15 \r\n",
       "L 225.403125 75.15 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_14\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m15526e4f85\" y=\"75.15\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_8\">\r\n",
       "      <!-- 0.6 -->\r\n",
       "      <g transform=\"translate(7.2 78.949219)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_3\">\r\n",
       "     <g id=\"line2d_15\">\r\n",
       "      <path clip-path=\"url(#p2e92b39dca)\" d=\"M 30.103125 29.85 \r\n",
       "L 225.403125 29.85 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_16\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m15526e4f85\" y=\"29.85\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_9\">\r\n",
       "      <!-- 0.8 -->\r\n",
       "      <g transform=\"translate(7.2 33.649219)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"line2d_17\">\r\n",
       "    <path clip-path=\"url(#p2e92b39dca)\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"line2d_18\">\r\n",
       "    <path clip-path=\"url(#p2e92b39dca)\" d=\"M 30.103125 41.797875 \r\n",
       "L 51.803125 26.894175 \r\n",
       "L 73.503125 23.942125 \r\n",
       "L 95.203125 22.6926 \r\n",
       "L 116.903125 21.292075 \r\n",
       "L 138.603125 20.672975 \r\n",
       "L 160.303125 20.076525 \r\n",
       "L 182.003125 19.608425 \r\n",
       "L 203.703125 19.09125 \r\n",
       "L 225.403125 18.7968 \r\n",
       "\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"line2d_19\">\r\n",
       "    <path clip-path=\"url(#p2e92b39dca)\" d=\"M 30.103125 32.9304 \r\n",
       "L 51.803125 30.3936 \r\n",
       "L 73.503125 27.60765 \r\n",
       "L 95.203125 24.34605 \r\n",
       "L 116.903125 23.53065 \r\n",
       "L 138.603125 23.84775 \r\n",
       "L 160.303125 23.4627 \r\n",
       "L 182.003125 23.71185 \r\n",
       "L 203.703125 22.4208 \r\n",
       "L 225.403125 22.12635 \r\n",
       "\" style=\"fill:none;stroke:#008000;stroke-dasharray:9.6,2.4,1.5,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_3\">\r\n",
       "    <path d=\"M 30.103125 143.1 \r\n",
       "L 30.103125 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_4\">\r\n",
       "    <path d=\"M 225.403125 143.1 \r\n",
       "L 225.403125 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_5\">\r\n",
       "    <path d=\"M 30.103125 143.1 \r\n",
       "L 225.403125 143.1 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_6\">\r\n",
       "    <path d=\"M 30.103125 7.2 \r\n",
       "L 225.403125 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"legend_1\">\r\n",
       "    <g id=\"patch_7\">\r\n",
       "     <path d=\"M 37.103125 138.1 \r\n",
       "L 114.871875 138.1 \r\n",
       "Q 116.871875 138.1 116.871875 136.1 \r\n",
       "L 116.871875 93.065625 \r\n",
       "Q 116.871875 91.065625 114.871875 91.065625 \r\n",
       "L 37.103125 91.065625 \r\n",
       "Q 35.103125 91.065625 35.103125 93.065625 \r\n",
       "L 35.103125 136.1 \r\n",
       "Q 35.103125 138.1 37.103125 138.1 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_20\">\r\n",
       "     <path d=\"M 39.103125 99.164062 \r\n",
       "L 59.103125 99.164062 \r\n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_21\"/>\r\n",
       "    <g id=\"text_10\">\r\n",
       "     <!-- train loss -->\r\n",
       "     <g transform=\"translate(67.103125 102.664062)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 18.3125 70.21875 \r\n",
       "L 18.3125 54.6875 \r\n",
       "L 36.8125 54.6875 \r\n",
       "L 36.8125 47.703125 \r\n",
       "L 18.3125 47.703125 \r\n",
       "L 18.3125 18.015625 \r\n",
       "Q 18.3125 11.328125 20.140625 9.421875 \r\n",
       "Q 21.96875 7.515625 27.59375 7.515625 \r\n",
       "L 36.8125 7.515625 \r\n",
       "L 36.8125 0 \r\n",
       "L 27.59375 0 \r\n",
       "Q 17.1875 0 13.234375 3.875 \r\n",
       "Q 9.28125 7.765625 9.28125 18.015625 \r\n",
       "L 9.28125 47.703125 \r\n",
       "L 2.6875 47.703125 \r\n",
       "L 2.6875 54.6875 \r\n",
       "L 9.28125 54.6875 \r\n",
       "L 9.28125 70.21875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-116\"/>\r\n",
       "       <path d=\"M 41.109375 46.296875 \r\n",
       "Q 39.59375 47.171875 37.8125 47.578125 \r\n",
       "Q 36.03125 48 33.890625 48 \r\n",
       "Q 26.265625 48 22.1875 43.046875 \r\n",
       "Q 18.109375 38.09375 18.109375 28.8125 \r\n",
       "L 18.109375 0 \r\n",
       "L 9.078125 0 \r\n",
       "L 9.078125 54.6875 \r\n",
       "L 18.109375 54.6875 \r\n",
       "L 18.109375 46.1875 \r\n",
       "Q 20.953125 51.171875 25.484375 53.578125 \r\n",
       "Q 30.03125 56 36.53125 56 \r\n",
       "Q 37.453125 56 38.578125 55.875 \r\n",
       "Q 39.703125 55.765625 41.0625 55.515625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-114\"/>\r\n",
       "       <path d=\"M 34.28125 27.484375 \r\n",
       "Q 23.390625 27.484375 19.1875 25 \r\n",
       "Q 14.984375 22.515625 14.984375 16.5 \r\n",
       "Q 14.984375 11.71875 18.140625 8.90625 \r\n",
       "Q 21.296875 6.109375 26.703125 6.109375 \r\n",
       "Q 34.1875 6.109375 38.703125 11.40625 \r\n",
       "Q 43.21875 16.703125 43.21875 25.484375 \r\n",
       "L 43.21875 27.484375 \r\n",
       "z\r\n",
       "M 52.203125 31.203125 \r\n",
       "L 52.203125 0 \r\n",
       "L 43.21875 0 \r\n",
       "L 43.21875 8.296875 \r\n",
       "Q 40.140625 3.328125 35.546875 0.953125 \r\n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \r\n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \r\n",
       "Q 6 8.015625 6 15.921875 \r\n",
       "Q 6 25.140625 12.171875 29.828125 \r\n",
       "Q 18.359375 34.515625 30.609375 34.515625 \r\n",
       "L 43.21875 34.515625 \r\n",
       "L 43.21875 35.40625 \r\n",
       "Q 43.21875 41.609375 39.140625 45 \r\n",
       "Q 35.0625 48.390625 27.6875 48.390625 \r\n",
       "Q 23 48.390625 18.546875 47.265625 \r\n",
       "Q 14.109375 46.140625 10.015625 43.890625 \r\n",
       "L 10.015625 52.203125 \r\n",
       "Q 14.9375 54.109375 19.578125 55.046875 \r\n",
       "Q 24.21875 56 28.609375 56 \r\n",
       "Q 40.484375 56 46.34375 49.84375 \r\n",
       "Q 52.203125 43.703125 52.203125 31.203125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-97\"/>\r\n",
       "       <path d=\"M 9.421875 54.6875 \r\n",
       "L 18.40625 54.6875 \r\n",
       "L 18.40625 0 \r\n",
       "L 9.421875 0 \r\n",
       "z\r\n",
       "M 9.421875 75.984375 \r\n",
       "L 18.40625 75.984375 \r\n",
       "L 18.40625 64.59375 \r\n",
       "L 9.421875 64.59375 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-105\"/>\r\n",
       "       <path d=\"M 54.890625 33.015625 \r\n",
       "L 54.890625 0 \r\n",
       "L 45.90625 0 \r\n",
       "L 45.90625 32.71875 \r\n",
       "Q 45.90625 40.484375 42.875 44.328125 \r\n",
       "Q 39.84375 48.1875 33.796875 48.1875 \r\n",
       "Q 26.515625 48.1875 22.3125 43.546875 \r\n",
       "Q 18.109375 38.921875 18.109375 30.90625 \r\n",
       "L 18.109375 0 \r\n",
       "L 9.078125 0 \r\n",
       "L 9.078125 54.6875 \r\n",
       "L 18.109375 54.6875 \r\n",
       "L 18.109375 46.1875 \r\n",
       "Q 21.34375 51.125 25.703125 53.5625 \r\n",
       "Q 30.078125 56 35.796875 56 \r\n",
       "Q 45.21875 56 50.046875 50.171875 \r\n",
       "Q 54.890625 44.34375 54.890625 33.015625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-110\"/>\r\n",
       "       <path id=\"DejaVuSans-32\"/>\r\n",
       "       <path d=\"M 9.421875 75.984375 \r\n",
       "L 18.40625 75.984375 \r\n",
       "L 18.40625 0 \r\n",
       "L 9.421875 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-108\"/>\r\n",
       "       <path d=\"M 44.28125 53.078125 \r\n",
       "L 44.28125 44.578125 \r\n",
       "Q 40.484375 46.53125 36.375 47.5 \r\n",
       "Q 32.28125 48.484375 27.875 48.484375 \r\n",
       "Q 21.1875 48.484375 17.84375 46.4375 \r\n",
       "Q 14.5 44.390625 14.5 40.28125 \r\n",
       "Q 14.5 37.15625 16.890625 35.375 \r\n",
       "Q 19.28125 33.59375 26.515625 31.984375 \r\n",
       "L 29.59375 31.296875 \r\n",
       "Q 39.15625 29.25 43.1875 25.515625 \r\n",
       "Q 47.21875 21.78125 47.21875 15.09375 \r\n",
       "Q 47.21875 7.46875 41.1875 3.015625 \r\n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \r\n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \r\n",
       "Q 10.6875 0.296875 5.421875 2 \r\n",
       "L 5.421875 11.28125 \r\n",
       "Q 10.40625 8.6875 15.234375 7.390625 \r\n",
       "Q 20.0625 6.109375 24.8125 6.109375 \r\n",
       "Q 31.15625 6.109375 34.5625 8.28125 \r\n",
       "Q 37.984375 10.453125 37.984375 14.40625 \r\n",
       "Q 37.984375 18.0625 35.515625 20.015625 \r\n",
       "Q 33.0625 21.96875 24.703125 23.78125 \r\n",
       "L 21.578125 24.515625 \r\n",
       "Q 13.234375 26.265625 9.515625 29.90625 \r\n",
       "Q 5.8125 33.546875 5.8125 39.890625 \r\n",
       "Q 5.8125 47.609375 11.28125 51.796875 \r\n",
       "Q 16.75 56 26.8125 56 \r\n",
       "Q 31.78125 56 36.171875 55.265625 \r\n",
       "Q 40.578125 54.546875 44.28125 53.078125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-115\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-116\"/>\r\n",
       "      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\r\n",
       "      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\r\n",
       "      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\r\n",
       "      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\r\n",
       "      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "      <use x=\"264.550781\" xlink:href=\"#DejaVuSans-108\"/>\r\n",
       "      <use x=\"292.333984\" xlink:href=\"#DejaVuSans-111\"/>\r\n",
       "      <use x=\"353.515625\" xlink:href=\"#DejaVuSans-115\"/>\r\n",
       "      <use x=\"405.615234\" xlink:href=\"#DejaVuSans-115\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_22\">\r\n",
       "     <path d=\"M 39.103125 113.842187 \r\n",
       "L 59.103125 113.842187 \r\n",
       "\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_23\"/>\r\n",
       "    <g id=\"text_11\">\r\n",
       "     <!-- train acc -->\r\n",
       "     <g transform=\"translate(67.103125 117.342187)scale(0.1 -0.1)\">\r\n",
       "      <use xlink:href=\"#DejaVuSans-116\"/>\r\n",
       "      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\r\n",
       "      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\r\n",
       "      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\r\n",
       "      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\r\n",
       "      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "      <use x=\"264.550781\" xlink:href=\"#DejaVuSans-97\"/>\r\n",
       "      <use x=\"325.830078\" xlink:href=\"#DejaVuSans-99\"/>\r\n",
       "      <use x=\"380.810547\" xlink:href=\"#DejaVuSans-99\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_24\">\r\n",
       "     <path d=\"M 39.103125 128.520312 \r\n",
       "L 59.103125 128.520312 \r\n",
       "\" style=\"fill:none;stroke:#008000;stroke-dasharray:9.6,2.4,1.5,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_25\"/>\r\n",
       "    <g id=\"text_12\">\r\n",
       "     <!-- test acc -->\r\n",
       "     <g transform=\"translate(67.103125 132.020312)scale(0.1 -0.1)\">\r\n",
       "      <use xlink:href=\"#DejaVuSans-116\"/>\r\n",
       "      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-101\"/>\r\n",
       "      <use x=\"100.732422\" xlink:href=\"#DejaVuSans-115\"/>\r\n",
       "      <use x=\"152.832031\" xlink:href=\"#DejaVuSans-116\"/>\r\n",
       "      <use x=\"192.041016\" xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "      <use x=\"223.828125\" xlink:href=\"#DejaVuSans-97\"/>\r\n",
       "      <use x=\"285.107422\" xlink:href=\"#DejaVuSans-99\"/>\r\n",
       "      <use x=\"340.087891\" xlink:href=\"#DejaVuSans-99\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       " </g>\r\n",
       " <defs>\r\n",
       "  <clipPath id=\"p2e92b39dca\">\r\n",
       "   <rect height=\"135.9\" width=\"195.3\" x=\"30.103125\" y=\"7.2\"/>\r\n",
       "  </clipPath>\r\n",
       " </defs>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import d2l.torch as d2l\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "\n",
    "\"\"\"搭建网络\"\"\"           ## 这里注意\n",
    "net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10)) ##展平向量\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "        \n",
    "net.apply(init_weights)     # 设置模型参数\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- softlabel\n",
    "- logistic regression 逻辑回归\n",
    "- 交叉熵，相对熵，互信息\n",
    "- 似然函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 多层感知机+代码实现\n",
    "## 感知机\n",
    "- 二分类：-1/1\n",
    " - 回归：实数\n",
    " - softmax回归：概率\n",
    " \n",
    "- 训练感知机\n",
    "   - 损失函数：$l(y,\\textbf{x},\\textbf{w}) = max(0, -y<\\textbf{w}, \\textbf{x}>)$  批量大小为1的梯度下降\n",
    "\n",
    "- 收敛定理\n",
    "  - 数据在r内\n",
    "  - 余量：$y(\\textbf{x}^T+\\textbf{b})\\ge \\rho$ （有限制条件）\n",
    "  - 感知机保证在$\\frac{r^2+1}{\\rho^2}$步后收敛\n",
    "\n",
    "- XOR问题：感知机不能拟合XOR函数，只能产生线性分割面\n",
    "\n",
    "\n",
    "## 多层感知机\n",
    "\n",
    "- 单隐藏层\n",
    "  - 非线性激活函数必须有：避免层数塌陷\n",
    "<img src=\"https://s2.loli.net/2022/02/09/aTU8mSJv5OhHi2I.png\" width=70%>\n",
    "  - sigmoid\n",
    "  - tanh\n",
    "  - ReLU\n",
    "\n",
    "- 多类分类\n",
    "<img src=\"https://s2.loli.net/2022/02/09/MnVRhjbkA3yGcLo.png\" width=70%>\n",
    "- 多隐藏层\n",
    "  - 超参数：隐层层数与隐藏层大小\n",
    "  - 选择：128-64-32-8-输出 (底层可以先expand)\n",
    "\n",
    "## 代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import d2l.torch as d2l\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_sizeh_size)\n",
    "\n",
    "num_inputs, num_hiddens, num_outputs = 784, 256, 10\n",
    "W1 = nn.Parameter(torch.randn(num_inputs, num_hiddens, requires_grad=True))\n",
    "W2 = nn.Parameter(torch.randn(num_hiddens, num_outputs, requires_grad=True))\n",
    "b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True))\n",
    "b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True))\n",
    "\n",
    "params = [W1, b1, W2, b2]   # 用nn.Parameter设定网络参数\n",
    "\n",
    "def relu(X):\n",
    "    a = torch.zeros_like(X)\n",
    "    return torch.max(X, a)  ##居然能比较大小属于是太牛了\n",
    "\n",
    "def net(X):\n",
    "    X = X.reshape((-1,num_inputs))  ## reshape遗漏\n",
    "    H = relu(X @ W1 + b1)           ## @：简写\n",
    "    return (H @ W2 + b2)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "epoch, lr = 10, 0.1\n",
    "trainer = torch.optim.SGD(params, lr=lr)\n",
    "d2l.train_ch3(net, train_itera, test_iter, loss, epoch, trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import d2l.torch as d2l\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_sizeh_size)\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Flatten(), nn.Linear(784, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "\n",
    "def init_weight(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "net.apply(init_weight)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "epoch, lr = 10, 0.1\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "d2l.train_ch3(net, train_itera, test_iter, loss, epoch, trainer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- svm与mlp、多层mlp\n",
    "- \"深度学习\"与\"浅度学习\"：理论上一样，实际一般深度较好\n",
    "- relu：引入非线性\n",
    "- 鲁棒、泛化、稳定性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 模型选择 + 过拟合和欠拟合\n",
    "## 模型选择\n",
    "- 训练误差$\\rightarrow$训练数据 和 泛化误差$\\rightarrow$新数据\n",
    "- 验证数据集$\\rightarrow$评估模型好坏 和 测试数据集$\\rightarrow$只用一次的数据集\n",
    "  - 验证：不要和训练混在一起；常拿出50%的训练数据\n",
    "  - 测试只能用一次！（举例数据：虚高）\n",
    "- K-折交叉验证\n",
    "  - 非大数据集上\n",
    "  - validation与train\n",
    "  - k个验证的精度/误差平均得loss\n",
    "     - 极端算法：尽可能使用数据集：n个数据，n折交叉验证\n",
    "\n",
    "## 过拟合和欠拟合\n",
    "- 过拟合和欠拟合\n",
    "  - 模型容量||数据 $\\rightarrow$ 正常/过拟合/欠拟合\n",
    "    - 过拟合：没有泛化性\n",
    "- 模型复杂度\n",
    "  - 模型容量：\n",
    "    - 拟合各种函数的能力\n",
    "    - 最优情况：泛化误差最小，训练误差还行\n",
    "      - 有时会选择承受一定的过拟合\n",
    "    - 估计模型容量：同种类算法：①参数个数 ②参数值范围 -->控制复杂度\n",
    "  - 统计学习：VC维\n",
    "     - 支持n维输入的感知机的VC维是N+1\n",
    "- 数据复杂度\n",
    "  - 个数，时空结构，多样性\n",
    "- 两个复杂度需要匹配\n",
    " \n",
    "\n",
    "## 代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 权重衰退\n",
    "处理过拟合\n",
    "- 使用均方误差范数作为硬性限制\n",
    " - $\\textbf{w}的L2 Loss\\le \\theta$; 更强的正则项\n",
    "- 使用均方误差作为柔性限制\n",
    "  $$minL(\\textbf{w},b) + \\frac{\\lambda}{2}\\textbf{w}的L2 Loss$$\n",
    "  - 超参数$\\lambda$控制了正则项的重要程度\n",
    "    - $\\lambda$ = 0：无作用\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
